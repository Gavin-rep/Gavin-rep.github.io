<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>文献阅读: SubspaceNet: Deep root music algorithm for data-driven DoA estimation | Gavin</title><meta name="author" content="Gavin"><meta name="copyright" content="Gavin"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="11 10 2023 ICASSP 摘要波达方向( Direction of Arrival，DoA )估计是阵列处理中的一项基本任务。子空间类方法是一类流行的DoA估计算法，它通过将测量值划分为不同的信号子空间和噪声子空间来操作。子空间类方法，如Root - MUSIC，要求信源是非相干的，当不成立时，就会严重退化。在这项工作中，我们提出了Deep Root MUSIC ( DR-MUSIC )">
<meta property="og:type" content="article">
<meta property="og:title" content="文献阅读: SubspaceNet: Deep root music algorithm for data-driven DoA estimation">
<meta property="og:url" content="http://example.com/2024/08/15/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%EF%BC%9ADeep%20root%20music%20algorithm%20for%20data-driven%20DoA%20estimation/index.html">
<meta property="og:site_name" content="Gavin">
<meta property="og:description" content="11 10 2023 ICASSP 摘要波达方向( Direction of Arrival，DoA )估计是阵列处理中的一项基本任务。子空间类方法是一类流行的DoA估计算法，它通过将测量值划分为不同的信号子空间和噪声子空间来操作。子空间类方法，如Root - MUSIC，要求信源是非相干的，当不成立时，就会严重退化。在这项工作中，我们提出了Deep Root MUSIC ( DR-MUSIC )">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://i.ibb.co/8xsnM1g/image.png">
<meta property="article:published_time" content="2024-08-15T13:06:33.318Z">
<meta property="article:modified_time" content="2024-10-27T13:51:35.564Z">
<meta property="article:author" content="Gavin">
<meta property="article:tag" content="深度学习">
<meta property="article:tag" content="开源代码">
<meta property="article:tag" content="DoA">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://i.ibb.co/8xsnM1g/image.png"><link rel="shortcut icon" href="https://i.ibb.co/3BGBwps/2c8b98a62fbc3615.png"><link rel="canonical" href="http://example.com/2024/08/15/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%EF%BC%9ADeep%20root%20music%20algorithm%20for%20data-driven%20DoA%20estimation/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '文献阅读: SubspaceNet: Deep root music algorithm for data-driven DoA estimation',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-10-27 21:51:35'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://i.ibb.co/0fP2mb0/image.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">29</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">18</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">2</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://i.ibb.co/8xsnM1g/image.png')"><nav id="nav"><span id="blog-info"><a href="/" title="Gavin"><img class="site-icon" src="https://i.ibb.co/3BGBwps/2c8b98a62fbc3615.png"/><span class="site-name">Gavin</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">文献阅读: SubspaceNet: Deep root music algorithm for data-driven DoA estimation</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-08-15T13:06:33.318Z" title="发表于 2024-08-15 21:06:33">2024-08-15</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-10-27T13:51:35.564Z" title="更新于 2024-10-27 21:51:35">2024-10-27</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB/">文献阅读</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="文献阅读: SubspaceNet: Deep root music algorithm for data-driven DoA estimation"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>11 10 2023 ICASSP</p>
<h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>波达方向( Direction of Arrival，DoA )估计是阵列处理中的一项基本任务。子空间类方法是一类流行的DoA估计算法，它通过将测量值划分为不同的信号子空间和噪声子空间来操作。子空间类方法，如Root - MUSIC，要求信源是非相干的，当不成立时，就会严重退化。在这项工作中，我们提出了Deep Root MUSIC ( DR-MUSIC )；一种基于数据驱动的DoA估计器，该估计器通过应用于输入的经验自相关的深度神经网络来增强Root - MUSIC。DR - MUSIC学习如何将观测数据划分到可区分的子空间，从而利用数据来应对相干源、低信噪比和有限快拍，同时保留了基于模型的算法的可解释性和适用性。</p>
<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>波达方向( Direction of Arrival，DoA )估计是一种常见的阵列处理任务，它通过确定入射波的入射角来定位发射源[ 1 ]。基于子空间方法的DoA估计器是一类领先且可信的DoA估计器，包括著名的多重信号分类( Multiple Signal Classification，MUSIC ) [ 2 ]和Root - MUSIC [ 3 ]算法。当给定足够多的信号快拍数时，这些技术通过将入射波分离成可区分的信号和噪声子空间，以较低的复杂度估计多个DoAs。这种分离依赖于噪声分量和阵列响应之间的正交性，在信号是窄带、非相干和统计模型完全已知的限制下。虽然已经提出了不同的预处理方法，如空间平滑( SPS )，以单独解决这些限制，例如[ 4、5]，但它们往往会降低整体估计性能和分辨率。</p>
<p>​	在过去的十年中，深度学习已经成为数据驱动推理的主要工具。因此，基于深度神经网络( deep neural network，DNN )的方法最近被考虑用于Do A估计[ 6-17 ]。具体来说，文献[ 6-11 ]训练了不同的DNN结构来学习映射将观测值或其经验协方差直接代入DoA。然而，基于端到端的深度学习的DoA估计需要使用海量数据集训练的高度参数化架构，同时缺乏基于模型的算法的可解释性和灵活性。</p>
<p>​	另一种方法是使用深度学习和基于模型的DoA估计。这些方法包括利用深度神经网络来限制最大似然检测的角度搜索空间[ 12 ]。在子空间方法的背景下，[ 13 ]训练了自编码器，从DoA估计任务中单独计算协方差，然后被MUSIC使用，而[ 14-16 ]使用DNNs产生(离散的)空间谱。然而，这些DNN辅助的估计器[ 13-15 ]没有被训练以提供DoAs，并且共享基于模型的子空间方法的局限性。工作[ 17 ]提出了一种架构，该架构联合学习计算经验协方差，并将结果频谱端到端的处理。而[ 17 ]在处理相干信源时，虽然实现了这一点，但同时损害了子空间方法的可解释性，并且无法从MUSIC谱中提取有意义的解释。这激励设计DNN辅助的DoA估计器，以应对相干信源和有限快拍，同时保留基于模型的子空间方法的可解释性。</p>
<p>​	在这里，我们提出了Deep Root-MUSIC ( DR-MUSIC )，一种基于Root - MUSIC的深度神经网络辅助系统，作为基于模型的深度学习[ 18、19]的一种形式。DR - MUSIC通过从数据中学习如何将经验自相关映射为一个对Root - MUSIC DoA估计有用的协方差表示，从而保留了基于模型方法的操作。与[ 17 ]不同的是，我们没有在可解释性上妥协，利用Root - MUSIC固有的可区分性，将算法转换为可训练的判别模型[ 20 ]。通过这样做，DR - MUSIC可以计算有意义的子空间表示和精确的DoA估计。我们的实验表明，DR - MUSIC方法在相干源和非相干源的情况下都优于基于模型的子空间方法，同时在噪声子空间和信号子空间之间建立了清晰和显著的区分，有利于其诊断和识别源的数量。本文其余部分安排如下：第2节阐述问题并回顾求根MUSIC。第3节介绍DR - MUSIC，第4节对其进行评估。</p>
<h2 id="系统模型和预备知识"><a href="#系统模型和预备知识" class="headerlink" title="系统模型和预备知识"></a>系统模型和预备知识</h2><h3 id="Doa估计问题的提法"><a href="#Doa估计问题的提法" class="headerlink" title="Doa估计问题的提法"></a>Doa估计问题的提法</h3><p>我们考虑了一个具有半波长间隔的$N$个天线的均匀线阵( ULA )的接收机。在每个时刻实例$t∈{ 1，..，T }$，接收者从$M$个入射源$\mathbf{s} ( t ) &#x3D; [ s_1 ( t ) , … , s_M ( t )]∈C^M$中获取多变量观测值$\mathbf{x} ( t ) &#x3D; [ x_1 ( t ) , … , x_N ( t )]∈C^N$，其中$DoAs \theta &#x3D; [ \theta_1 , … , \theta_M]$未知。发射信号为窄带且处于阵列的远场。得到的接收信号在$T$个快拍下，记为$\mathbf{X} &#x3D; [ \mathbf{x} ( 1 ) , … , \mathbf{x} ( T )]∈C^{N × T}$满足</p>
<img src="https://cdn.jsdelivr.net/gh/Gavin-rep/Pictures@master/image-20240818140802561.png" alt="image-20240818140802561" style="zoom:50%;" />

<p>在( 1 )中，$\mathbf{S} &#x3D; [\mathbf{s} ( 1 ) , … , \mathbf{s} ( T )]∈C^{M × T}$是源信号矩阵；$\mathbf{V} &#x3D; [ \mathbf{v} ( 1 ) , … , \mathbf{v} ( T )]∈C^{N × T}$是由方差为$σ _V^2$的i . i . d .项组成的噪声矩阵；和$\mathbf{A} ( \theta ) &#x3D; [ \mathbf{a} ( \theta_1 ) , … , \mathbf{a} ( \theta_M )]∈C^{N × M}$为导向矩阵，其中</p>
<img src="https://cdn.jsdelivr.net/gh/Gavin-rep/Pictures@master/image-20240818141005556.png" alt="image-20240818141005556" style="zoom:50%;" />

<p>​	当信源是平稳和非相干的时，由( 1 )式可知，观测值的协方差为</p>
<img src="https://cdn.jsdelivr.net/gh/Gavin-rep/Pictures@master/image-20240818141027381.png" alt="image-20240818141027381" style="zoom:50%;" />

<p>其中$\mathbf{s}(t)$ 的协方差$\mathbf{R}_S$ 为对角矩阵。</p>
<p>​	DoA估计考虑从$T$个快拍数$\mathbf{X}$上得到的观测值中恢复$\theta$，信源可以是相干的，快拍数$T$可能很小。为了处理这些具有挑战性的场景，我们利用了由$J$对观测和它们对应的DoAs组成的数据，记为$D &#x3D; { ( \mathbf{X}_j , \theta_j) } ^J _{j &#x3D; 1}$。我们在第3节中提出的方案是建立在Root - MUSIC的基础上的，在下文中不再赘述。</p>
<h3 id="Root-MUSIC-算法"><a href="#Root-MUSIC-算法" class="headerlink" title="Root-MUSIC 算法"></a>Root-MUSIC 算法</h3><p>Root - MUSIC是一种DoA估计算法，属于子空间方法家族。这些方案利用了在( 3 )中的观测协方差模型下，$\mathbf{R}_{\mathbf{X}}$的特征向量$\mathbf{U} &#x3D; [ \mathbf{u}_1 , … , \mathbf{u}_N]$是相互正交的，并且可以分为信号子空间和噪声子空间[ 2 ]这一事实。前者由导向矩阵$\mathbf{A} ( \theta )$的列张成，后者由$( N-M) × N$矩阵$\mathbf{U}<em>N$表示，由$\mathbf{R}</em>{\mathbf{X}}$的$N - M$个最小主特征值对应的特征向量组成.因此，</p>
<img src="https://cdn.jsdelivr.net/gh/Gavin-rep/Pictures@master/image-20240818141433303.png" alt="image-20240818141433303" style="zoom:50%;" />

<p>​	利用式( 4 )中的正交性，利用式( 3 )对相干信源的正交性，采用子空间方法进行DOA估计。Root-MUSIC (以及MUSIC )，首先得到( 3 )式的经验估计值$\hat{\mathbf{R}_X} &#x3D; \frac{1}{T}\mathbf{X}\mathbf{X}^H$。然后，对其进行特征值分解( EVD )，从EVD中估计出源信号的个数$\hat{M}$ 为主导特征值个数(例如,通过阈值化) )，而剩余的$N - \hat{M}$ 个特征值对应的特征向量被用来构成估计的噪声子空间矩阵$\hat{\mathbf{U}} _ N $。Root - MUSIC通过求( 4 )式的根，利用估计出的$\hat{\mathbf{U}}_N $来恢复DoAs。特别地，Root - MUSIC利用其对角和系数$f_n$通过构造Hermitian矩阵$\mathbf{F} &#x3D; \hat{\mathbf{U}} _N\hat{\mathbf{U}} ^H_N $。</p>
<img src="https://cdn.jsdelivr.net/gh/Gavin-rep/Pictures@master/image-20240818142712288.png" alt="image-20240818142712288" style="zoom:50%;" />

<p>其中对于$n &lt;0, f_n &#x3D; f_{|n|}^*$ ，将(5) 插入(4) 式中，(4)的左边可以被表示为一个阶数为$2N-2$的多项式方程:</p>
<img src="https://cdn.jsdelivr.net/gh/Gavin-rep/Pictures@master/image-20240818142815528.png" alt="image-20240818142815528" style="zoom:50%;" />

<p>其中有$z &#x3D; e^{-j\pi sin(\theta)}$ ，因此，Root - MUSIC从多项式( 6 )的根中识别出DoAs，并将根映射看作Root - MUSIC谱。由于( 6 )有$2N - 2 &gt; M$个根(分为对称对)，而对应于DoAs的根应该具有单位数量级，因此$\hat{M}$  (离单位圆最近的根对)被匹配为$\hat{M}$源DoAs [ 3 ] .图1给出了该方法的程序框图。</p>
<img src="https://cdn.jsdelivr.net/gh/Gavin-rep/Pictures@master/image-20240818143024846.png" alt="image-20240818143024846" style="zoom:50%;" />

<h2 id="Deep-ROOT-MUSIC"><a href="#Deep-ROOT-MUSIC" class="headerlink" title="Deep ROOT-MUSIC"></a>Deep ROOT-MUSIC</h2><p>Root - MUSIC是一种可靠的DoA估计方法，其频谱为DoA和不确定性度量提供了一种可解释的可视化。然而，它依赖于足够快照的可用性来可靠地估计( 3 )；非相干源能够将式( 3 )分解成子空间；高信噪比( signal-to-noise ratio，SNR )使( 6 )式的根与DoAs可靠关联。为了克服这些挑战，同时保留Root - MUSIC的运算，我们接下来提出了DR - MUSIC。我们首先在第3.1 - 3.2节分别介绍架构及其训练，然后在第3.3节进行讨论。</p>
<h3 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h3><p>DR - MUSIC是Root - MUSIC的深度学习扩展。它基于这样的见解，Root - MUSIC的上述挑战可以通过为算法提供一个代理协方差矩阵来解决，该矩阵有利于信号和噪声子空间的划分。为了达到这个目的，我们使用专用的DNN从数据中学习以产生所需的协方差。与文献[ 17 ]不同的是，这里我们利用( 6 )式的根关于$\mathbf{F}$的项的可微性，在不修改Root - MUSIC的情况下实现端到端的学习。</p>
<p>​	我们从聚焦技术中获得灵感[ 21 ]，最初设计用于将宽带设置转换为替代窄带设置。我们设计了我们的架构，从$\mathbf{X}$的经验自相关中获得代理协方差，计算为</p>
<img src="https://cdn.jsdelivr.net/gh/Gavin-rep/Pictures@master/image-20240818143223186.png" alt="image-20240818143223186" style="zoom:50%;" />

<p>​	使用去噪自编码器实现${\hat{\mathbf{R}} _ X [ τ ] }^{τ_{max}}_{τ &#x3D; 0}$到替代协方差的映射。这类DNN通常用于从含噪数据中进行特征选择，转化为高维表示[ 22 , Ch . 14 ]。我们使用基于卷积神经网络( CNN )的自编码器将$N × N$的自相关矩阵(分解为实部和虚部分量)处理成$2N × N$的实数矩阵，并将其改写成复数矩阵$\mathbf{K}∈C^{N × N}$。为了能够得到可替代的矩阵，$\mathbf{K}$ 被转换为一个Hermitian 正定协方差估计通过如下公式：</p>
<img src="https://cdn.jsdelivr.net/gh/Gavin-rep/Pictures@master/image-20240818143507138.png" alt="image-20240818143507138" style="zoom:50%;" />

<p>这里的$\tau_{max}$ 和$\epsilon$ 均为架构的超参数，可替代协方差$\hat{\mathbf{R}}$ 基于模型的Root-MUSIC处理，其架构在图二中表示：</p>
<img src="https://cdn.jsdelivr.net/gh/Gavin-rep/Pictures@master/image-20240818143619304.png" alt="image-20240818143619304" style="zoom:50%;" />

<h3 id="训练过程"><a href="#训练过程" class="headerlink" title="训练过程"></a>训练过程</h3><p>选择Root - MUSIC作为我们的基于模型的DoA估计器，并使用深度学习进行增强，其核心源于其映射的可区分性。特别地，DoA估计由( 6 )式的根给出，即由一个隐式多项式函数给出，可以通过隐式微分计算关于系数${ f_n }$的导数。该特性允许DR - MUSIC端到端的DNN参数优化[ 23 ]，即通过图2中的Root - MUSIC块反向传播。</p>
<p>​	上述性质允许利用数据D进行DR - MUSIC的监督学习。由于DoAs是定义在一个周期范围内，我们使用均方根周期误差( RMSPE )损失[ 24 ]，它计算一个周期范围内的元素级损失。进一步地，我们考虑到估计的DoAs的顺序并不影响其表现。因此，该损失将所有可用的DoAs预测组合与基本真值标签进行比较，将DoA估计值与一个矩形二进制置换矩阵 $\mathbf{P}$相乘，每一行和每一列恰有一个1的条目。令P为这样的$M × M$个排列的集合，由此得到的损失测度为：</p>
<img src="https://cdn.jsdelivr.net/gh/Gavin-rep/Pictures@master/image-20240818143959280.png" alt="image-20240818143959280" style="zoom:50%;" />

<h3 id="讨论"><a href="#讨论" class="headerlink" title="讨论"></a>讨论</h3><p>所提出的DR - MUSIC利用数据应用深度学习工具，使Root - MUSIC能够在相干信源、有限快拍和低信噪比的情况下可靠地运行。这是通过确定处理这些挑战的难度与协方差矩阵的计算相关，并仅通过专用的DNN架构来增加这种特定的计算来实现的。与[ 17 ]不同，[ 17 ]专注于MUSIC，并且必须修改其操作来进行训练，Root - MUSIC的继承可微性允许在不影响计算协方差如何处理的情况下对架构进行端到端的训练。</p>
<p>​	我们的设计重点是利用数据来应对噪声相干源和有限的快照。然而，DR - MUSIC从数据中学习到的替代协方差的能力表明它可以用于处理宽带信号，以及应对阵列几何失配。进一步地，DR - MUSIC能够学习产生一个协方差矩阵，该协方差矩阵可以分解为信号子空间和噪声子空间，这促使其扩展到其他子空间方法。这些扩展留待以后的研究。</p>
<h2 id="经验研究"><a href="#经验研究" class="headerlink" title="经验研究"></a>经验研究</h2><p>在这一部分，我们对DR - MUSIC进行了实验评估，并将其与基于模型( MB )的MUSIC和Root - MUSIC方法进行了比较。考虑$N &#x3D; 8$个阵元的ULA处理冲击信号，如式( 1 )所示。接收信号和噪声都是从零均值复高斯分布中独立随机抽取的，方差分别为1和$σ _V^2$；SNR定义为$1 &#x2F; σ _V^2$。DoAs是由区间$[ -\frac{π}{2} , \frac{π}{2}]$均匀产生的。 </p>
<p>​	DR - MUSIC算法使用的自编码器由3个卷积层(具有16、32、64个输出通道)实现，后接3个反卷积层(具有32、16、1个输出通道)，核大小为2 × 2。其次，它与基于模型的Root-MUSIC和通过$0.5 °$分辨率的一维网格搜索实现的MUSIC [ 2 ]进行了比较。对于相干信源，我们也采用了基于模型的带有空间平滑( SPS )预处理的benchmarks，常用于此类情况下的[ 4、5]。</p>
<p>​	首先，在SNR为10dB的条件下，评估DR - MUSIC算法对$T &#x3D; 100$快拍相干信源的DOA估计性能。在表1中报告的RMSPE表明，DR - MUSIC显著优于基于模型的估计器，表明其DNN增强使其能够成功地处理相干源。我们在具有挑战性的环境中评估DR - MUSIC，在相干源和非相干源的低信噪比( 3a )下，只有$T &#x3D; 20$和$T &#x3D; 2$快拍数(图。3b ~ 3c)。</p>
<img src="https://cdn.jsdelivr.net/gh/Gavin-rep/Pictures@master/image-20240818144515062.png" alt="image-20240818144515062" style="zoom:50%;" />

<p><img src="https://cdn.jsdelivr.net/gh/Gavin-rep/Pictures@master/image-20240818144731303.png" alt="image-20240818144731303"></p>
<p>观察图3，我们注意到DR - MUSIC成功地处理了低信噪比和少快拍的情况，特别是优于MUSIC和ROOT-MUSIC,不仅对于相干信源，他们通常struggle的地方，而且对于非相干信源。</p>
<p>​	DR - MUSIC算法保留了Root - MUSIC算法的可解释性，利用DNN得到替代协方差，便于划分噪声子空间和信号子空间。接下来，我们数值评估了DR - MUSIC的这一特性，固定SNR为10 dB，$T &#x3D; 100$。我们首先比较了Root - MUSIC和DR - MUSIC对$M &#x3D; 3$相干信源产生的协方差特征值的大小。如图4所示，DR - MUSIC的结果表明，信号子空间的主特征值和代表噪声的主特征值之间有明显的区别。与基于模型的Root - MUSIC相比，这显著地有利于识别相干信源。</p>
<img src="https://cdn.jsdelivr.net/gh/Gavin-rep/Pictures@master/image-20240818145055306.png" alt="image-20240818145055306" style="zoom:50%;" />

<p>​	为了估计位于$θ &#x3D; [ 12.51 ° , 89.11 °]$处的$M &#x3D; 2$相干信源，我们进一步在图5中可视化了DR - MUSIC产生的根。观察到DR - MUSIC产生一个可解释的频谱，其中最接近单位圆的根代表真实的DoAs。此外，与Root - MUSIC相比，DR - MUSIC产生的频谱更容易区分与DoAs相关的根。图5中的红色箭头突出显示了如何将非DoA根推到远离单位圆的位置，以方便它们的区分，并在处理相干源时产生可解释的Root - MUSIC谱。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Gavin-rep/Pictures@master/image-20240818145213280.png" alt="image-20240818145213280"></p>
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>我们提出了DR - MUSIC，它是通过深度学习工具对Root - MUSIC进行增强，将其转换为可训练结构而设计的DoA估计器。DR - MUSIC利用数据学习将观测值划分为信号子空间和噪声子空间。我们的结果证明了它能够成功地处理相干源，低信噪比和少量快拍，同时保留了Root - MUSIC的可解释性。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="http://example.com">Gavin</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://example.com/2024/08/15/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%EF%BC%9ADeep%20root%20music%20algorithm%20for%20data-driven%20DoA%20estimation/">http://example.com/2024/08/15/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%EF%BC%9ADeep%20root%20music%20algorithm%20for%20data-driven%20DoA%20estimation/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://example.com" target="_blank">Gavin</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><a class="post-meta__tags" href="/tags/%E5%BC%80%E6%BA%90%E4%BB%A3%E7%A0%81/">开源代码</a><a class="post-meta__tags" href="/tags/DoA/">DoA</a></div><div class="post_share"><div class="social-share" data-image="https://i.ibb.co/8xsnM1g/image.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2024/08/25/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93%EF%BC%9A%E4%B8%8D%E5%90%8C%E7%9A%84dB/" title="知识总结：不同的dB"><img class="cover" src="https://i.ibb.co/wBsWFc5/image.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">知识总结：不同的dB</div></div></a></div><div class="next-post pull-right"><a href="/2024/07/13/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%EF%BC%9A%20Analysis%20and%20control%20of%20multi-zone%20sound%20field%20reproduction%20using%20modal-domain%20approach/" title="文献阅读:Analysis and control of multi-zone sound field reproduction using modal-domain approach"><img class="cover" src="https://i.ibb.co/z2zkhRs/image.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">文献阅读:Analysis and control of multi-zone sound field reproduction using modal-domain approach</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2024/05/06/%20%20%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB-%20Real-time%20implementation%20and%20explainable%20AI%20analysis%20of%20delayless%20CNN-based%20selective%20fixed-filter%20active%20noise%20control/" title="文献阅读: Real-time implementation and explainable AI analysis of delayless CNN-based selective fixed-filter active noise control"><img class="cover" src="https://i.ibb.co/rk6B9g0/image.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-05-06</div><div class="title">文献阅读: Real-time implementation and explainable AI analysis of delayless CNN-based selective fixed-filter active noise control</div></div></a></div><div><a href="/2024/05/06/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%EF%BC%9A%20Transferable%20Latent%20of%20CNN-Based%20Selective%20Fixed-Filter%20Active%20Noise%20Control/" title="文献阅读: Transferable Latent of CNN-Based Selective Fixed-Filter Active Noise Control"><img class="cover" src="https://i.ibb.co/xSTFTsh/image.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-05-06</div><div class="title">文献阅读: Transferable Latent of CNN-Based Selective Fixed-Filter Active Noise Control</div></div></a></div><div><a href="/2024/04/23/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%EF%BC%9AA%20Hybrid%20SFANC-FxNLMS%20Algorithm%20for%20Active%20Noise%20Control%20based%20on%20Deep%20Learning/" title="文献阅读: A Hybrid SFANC-FxNLMS Algorithm for Active Noise Control based on Deep Learning"><img class="cover" src="https://i.ibb.co/5GmwJBS/image.png	" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-04-23</div><div class="title">文献阅读: A Hybrid SFANC-FxNLMS Algorithm for Active Noise Control based on Deep Learning</div></div></a></div><div><a href="/2024/05/05/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%EF%BC%9ADEEP%20GENERATIVE%20FIXED-FILTER%20ACTIVE%20NOISE%20CONTROL/" title="文献阅读: DEEP GENERATIVE FIXED-FILTER ACTIVE NOISE CONTROL"><img class="cover" src="https://i.ibb.co/LSLjfkw/image.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-05-05</div><div class="title">文献阅读: DEEP GENERATIVE FIXED-FILTER ACTIVE NOISE CONTROL</div></div></a></div><div><a href="/2024/01/13/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93%EF%BC%9A%E5%9F%BA%E4%BA%8E%E7%90%83%E9%BA%A6%E5%85%8B%E9%A3%8E%E9%98%B5%E5%88%97%E7%9A%84%E5%A3%B0%E6%BA%90DoA%E4%BC%B0%E8%AE%A1/" title="知识总结: 基于球麦克风阵列的声源DoA估计"><img class="cover" src="https://i.ibb.co/1dkyDjy/acoustic-camera-gfaitech-Sphere120-beamforming-microphone-array-3d-measurement-interior-right.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-01-13</div><div class="title">知识总结: 基于球麦克风阵列的声源DoA估计</div></div></a></div><div><a href="/2024/11/17/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%EF%BC%9AMasked%20Autoencoders%20Are%20Scalable%20Vision%20Learners%20/" title="文献阅读: Masked Autoencoders Are Scalable Vision Learners"><img class="cover" src="https://i.ibb.co/gD7cJGh/image.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-11-17</div><div class="title">文献阅读: Masked Autoencoders Are Scalable Vision Learners</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://i.ibb.co/0fP2mb0/image.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Gavin</div><div class="author-info__description">我的过去常常追赶着我</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">29</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">18</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">2</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/alexandergwm"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/alexandergwm" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:wenmiaogao@163.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">May you stay young forever, do the thing in your own zone.</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%91%98%E8%A6%81"><span class="toc-number">1.</span> <span class="toc-text">摘要</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%8B%E7%BB%8D"><span class="toc-number">2.</span> <span class="toc-text">介绍</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%B3%BB%E7%BB%9F%E6%A8%A1%E5%9E%8B%E5%92%8C%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86"><span class="toc-number">3.</span> <span class="toc-text">系统模型和预备知识</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Doa%E4%BC%B0%E8%AE%A1%E9%97%AE%E9%A2%98%E7%9A%84%E6%8F%90%E6%B3%95"><span class="toc-number">3.1.</span> <span class="toc-text">Doa估计问题的提法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Root-MUSIC-%E7%AE%97%E6%B3%95"><span class="toc-number">3.2.</span> <span class="toc-text">Root-MUSIC 算法</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Deep-ROOT-MUSIC"><span class="toc-number">4.</span> <span class="toc-text">Deep ROOT-MUSIC</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9E%B6%E6%9E%84"><span class="toc-number">4.1.</span> <span class="toc-text">架构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B"><span class="toc-number">4.2.</span> <span class="toc-text">训练过程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%A8%E8%AE%BA"><span class="toc-number">4.3.</span> <span class="toc-text">讨论</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BB%8F%E9%AA%8C%E7%A0%94%E7%A9%B6"><span class="toc-number">5.</span> <span class="toc-text">经验研究</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BB%93%E8%AE%BA"><span class="toc-number">6.</span> <span class="toc-text">结论</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2024/12/15/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%EF%BC%9AA%20Hybrid%20DSP:Deep%20Learning%20Approach%20to%20%20Real-Time%20Full-Band%20Speech%20Enhancement/" title="文献阅读: A Hybrid DSP/Deep Learning Approach to  Real-Time Full-Band Speech Enhancement"><img src="https://i.ibb.co/VYX8yFsD/image.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="文献阅读: A Hybrid DSP/Deep Learning Approach to  Real-Time Full-Band Speech Enhancement"/></a><div class="content"><a class="title" href="/2024/12/15/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%EF%BC%9AA%20Hybrid%20DSP:Deep%20Learning%20Approach%20to%20%20Real-Time%20Full-Band%20Speech%20Enhancement/" title="文献阅读: A Hybrid DSP/Deep Learning Approach to  Real-Time Full-Band Speech Enhancement">文献阅读: A Hybrid DSP/Deep Learning Approach to  Real-Time Full-Band Speech Enhancement</a><time datetime="2024-12-15T04:12:53.312Z" title="发表于 2024-12-15 12:12:53">2024-12-15</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/11/19/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%EF%BC%9AMasked%20Autoencoders%20that%20listen/" title="文献阅读: Masked Autoencoders that Listen"><img src="https://i.ibb.co/9HZr35S/image.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="文献阅读: Masked Autoencoders that Listen"/></a><div class="content"><a class="title" href="/2024/11/19/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%EF%BC%9AMasked%20Autoencoders%20that%20listen/" title="文献阅读: Masked Autoencoders that Listen">文献阅读: Masked Autoencoders that Listen</a><time datetime="2024-11-19T13:34:57.816Z" title="发表于 2024-11-19 21:34:57">2024-11-19</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/11/17/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%EF%BC%9AMasked%20Autoencoders%20Are%20Scalable%20Vision%20Learners%20/" title="文献阅读: Masked Autoencoders Are Scalable Vision Learners"><img src="https://i.ibb.co/gD7cJGh/image.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="文献阅读: Masked Autoencoders Are Scalable Vision Learners"/></a><div class="content"><a class="title" href="/2024/11/17/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%EF%BC%9AMasked%20Autoencoders%20Are%20Scalable%20Vision%20Learners%20/" title="文献阅读: Masked Autoencoders Are Scalable Vision Learners">文献阅读: Masked Autoencoders Are Scalable Vision Learners</a><time datetime="2024-11-17T12:30:01.804Z" title="发表于 2024-11-17 20:30:01">2024-11-17</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/10/27/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%20-%20Robustness%20and%20Regularization%20of%20Personal%20Audio%20Systems/" title="文献阅读: Robustness and Regularization of Personal Audio Systems"><img src="https://i.ibb.co/c1YpYsm/image.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="文献阅读: Robustness and Regularization of Personal Audio Systems"/></a><div class="content"><a class="title" href="/2024/10/27/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%20-%20Robustness%20and%20Regularization%20of%20Personal%20Audio%20Systems/" title="文献阅读: Robustness and Regularization of Personal Audio Systems">文献阅读: Robustness and Regularization of Personal Audio Systems</a><time datetime="2024-10-27T13:47:25.740Z" title="发表于 2024-10-27 21:47:25">2024-10-27</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/08/25/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93%EF%BC%9A%E4%B8%8D%E5%90%8C%E7%9A%84dB/" title="知识总结：不同的dB"><img src="https://i.ibb.co/wBsWFc5/image.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="知识总结：不同的dB"/></a><div class="content"><a class="title" href="/2024/08/25/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93%EF%BC%9A%E4%B8%8D%E5%90%8C%E7%9A%84dB/" title="知识总结：不同的dB">知识总结：不同的dB</a><time datetime="2024-08-25T08:12:47.278Z" title="发表于 2024-08-25 16:12:47">2024-08-25</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2025 By Gavin</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">Have a nice day!</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, '']
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typesetPromise()
}</script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex/dist/contrib/copy-tex.min.js"></script><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', { class: 'katex-wrap'})
  })
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>