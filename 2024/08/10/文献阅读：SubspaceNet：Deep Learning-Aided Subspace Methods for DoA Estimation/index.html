<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>文献阅读: SubspaceNet: Deep Learning-Aided Subspace Methods for DoA Estimation | Gavin</title><meta name="author" content="Gavin"><meta name="copyright" content="Gavin"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="11 July 2024 Arxiv 摘要​	到达方向（DoA）估计是阵列处理的一项基本任务。子空间方法是一种常用的到达方向估计算法，它通过将测量结果划分为不同的信号和噪声子空间来实现。子空间方法，如多信号分类（MUSIC）和Root-MUSIC，依赖于几个限制性假设，包括窄带非相干源和完全校准阵列，当这些假设不成立时，其性能会大大降低。在这项工作中，我们提出了 SubspaceNet；这是一种数">
<meta property="og:type" content="article">
<meta property="og:title" content="文献阅读: SubspaceNet: Deep Learning-Aided Subspace Methods for DoA Estimation">
<meta property="og:url" content="http://example.com/2024/08/10/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%EF%BC%9ASubspaceNet%EF%BC%9ADeep%20Learning-Aided%20Subspace%20Methods%20for%20DoA%20Estimation/index.html">
<meta property="og:site_name" content="Gavin">
<meta property="og:description" content="11 July 2024 Arxiv 摘要​	到达方向（DoA）估计是阵列处理的一项基本任务。子空间方法是一种常用的到达方向估计算法，它通过将测量结果划分为不同的信号和噪声子空间来实现。子空间方法，如多信号分类（MUSIC）和Root-MUSIC，依赖于几个限制性假设，包括窄带非相干源和完全校准阵列，当这些假设不成立时，其性能会大大降低。在这项工作中，我们提出了 SubspaceNet；这是一种数">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://i.ibb.co/HNzMHrZ/image.png">
<meta property="article:published_time" content="2024-08-10T12:41:16.825Z">
<meta property="article:modified_time" content="2024-08-12T11:11:31.186Z">
<meta property="article:author" content="Gavin">
<meta property="article:tag" content="深度学习">
<meta property="article:tag" content="开源代码">
<meta property="article:tag" content="DoA">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://i.ibb.co/HNzMHrZ/image.png"><link rel="shortcut icon" href="https://i.ibb.co/3BGBwps/2c8b98a62fbc3615.png"><link rel="canonical" href="http://example.com/2024/08/10/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%EF%BC%9ASubspaceNet%EF%BC%9ADeep%20Learning-Aided%20Subspace%20Methods%20for%20DoA%20Estimation/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '文献阅读: SubspaceNet: Deep Learning-Aided Subspace Methods for DoA Estimation',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-08-12 19:11:31'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://i.ibb.co/ch2RrDp/20230822001522.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">32</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">14</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">3</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://i.ibb.co/HNzMHrZ/image.png')"><nav id="nav"><span id="blog-info"><a href="/" title="Gavin"><img class="site-icon" src="https://i.ibb.co/3BGBwps/2c8b98a62fbc3615.png"/><span class="site-name">Gavin</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">文献阅读: SubspaceNet: Deep Learning-Aided Subspace Methods for DoA Estimation</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-08-10T12:41:16.825Z" title="发表于 2024-08-10 20:41:16">2024-08-10</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-08-12T11:11:31.186Z" title="更新于 2024-08-12 19:11:31">2024-08-12</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB/">文献阅读</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="文献阅读: SubspaceNet: Deep Learning-Aided Subspace Methods for DoA Estimation"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>11 July 2024 Arxiv</p>
<h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>​	到达方向（DoA）估计是阵列处理的一项基本任务。子空间方法是一种常用的到达方向估计算法，它通过将测量结果划分为不同的信号和噪声子空间来实现。子空间方法，如多信号分类（MUSIC）和Root-MUSIC，依赖于几个限制性假设，包括窄带非相干源和完全校准阵列，当这些假设不成立时，其性能会大大降低。在这项工作中，我们提出了 SubspaceNet；这是一种数据驱动的 DoA 估计器，可学习如何将观测数据划分为可区分的子空间。这是通过利用专用的深度神经网络学习输入的经验自相关性来实现的，方法是将其作为 Root-MUSIC 方法的一部分进行训练，利用这种特定 DoA 估计器固有的可区分性，同时无需提供地面真实的可分解自相关矩阵。训练完成后，生成的 SubspaceNet 将成为通用的替代协方差估计器，可与任何基于子空间的 DoA 估计方法结合使用，从而在具有挑战性的设置中成功应用。研究表明，SubspaceNet 使各种 DoA 估算算法能够应对相干源、宽带信号、低 SNR、阵列不匹配和有限快照等问题，同时保留了经典子空间方法的可解释性和适用性。</p>
<h2 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1. 介绍"></a>1. 介绍</h2><p>​	到达方向（DoA）估计是一项常见的阵列处理任务，它通过确定入射波的入射角来定位发射源[2]。基于子空间方法的到达方向估计器是一个领先且可靠的系列，包括著名的多信号分类（MUSIC）算法[3]、根-MUSIC（Root-MUSIC）[4]和通过旋转不变性技术估计信号参数（ESPRIT）[5]。在给定足够的信号快照时，这些技术通过将入射波分离成可区分的信号和噪声子空间，以较低的复杂度估算出多个 DoAs，从而实现不受阵列几何限制的角度分辨率[2]。</p>
<p>​	将入射波分离为信号子空间和噪声子空间的能力是子空间方法的核心，它依赖于噪声分量和阵列响应之间的正交性。要做到这一点，必须满足子空间方法的几个关键假设： (i) 信号必须是窄带的；(ii) 信号源必须是非相干的；(iii) 阵列必须经过充分校准; (iv) 需要有足够多的snapshots，使得估计输入协方差时有效的; (v) 估算程序所依据的统计模型必须完全已知。在实际应用中，这些要求经常被违反，因为实际应用中经常涉及多频带信号、相干信号源（如多径信号）、阵列误判、有限快照和不匹配模型。人们提出了不同的预处理方法，如空间平滑法（SPS）和前向后退法（FB），以单独解决其中的一些限制，如 [6]、[7]。这些方案将接收信号的功率谱平均到多个相邻的传感器位置上，从而增加有效孔径，同时在分辨率和方差减小之间进行权衡。具体来说，平均窗口越大，降低方差的效果越好，但分辨率越低；窗口越小，分辨率越高，但降低方差的效果越差。因此，它们往往会降低整体估计性能和分辨率，同时限制可恢复源的数量。 </p>
<p>​	在过去十年中，深度学习已成为数据驱动推理的主要工具。深度神经网络（DNN）无需依赖系统建模即可从数据中学习映射，在计算机视觉等涉及复杂数据的领域取得了前所未有的成功[8]。因此，基于 DNN 的方法最近被用于 DoA 估算 [9]-[31]，[32] 也对其进行了研究。具体来说，[9]-[18] 中训练了不同的 DNN 架构，如多层感知器（MLP）[9]、[10]、卷积神经网络（CNN）[11]-[16]、注意力模型[17]和 ResNet 变体[18]，以学习从观测值或其经验协方差直接到 DoAs 的映射。虽然 DNNs 可以在不对信号模型施加特定要求的情况下进行训练以估计 DoA，但它们通常需要使用海量数据集进行训练的高度参数化架构，这限制了它们在硬件有限的设备上的适用性，而 DoA 估计通常是在这些设备上进行的。此外，黑盒 DNN 缺乏基于模型算法的可解释性和灵活性，往往会产生泛化问题。</p>
<p>​	一种替代方法是将深度神经网络（DNN）与基于模型的方向估计（DoA）相结合，作为一种基于模型的深度学习形式。例如，文献[19]通过使用DNN来限制角度搜索空间，从而减少最大似然DoA恢复的复杂性，但仍依赖于信号的精确统计建模。文献[25]–[27]则训练了DNN架构，以生成可以用于后续基于子空间的DoA估计的干净协方差矩阵，同时假设可以访问由理想协方差组成的数据集，从而可以单独训练DNN。文献[20]利用窄带信号建模，以无监督的方式训练基于CNN的DoA估计器。在子空间方法的背景下，文献[21]训练了一个自动编码器来从被污染的输入中重建一个干净的输入，然后将其传递给多层感知机（MLP）分类器以重建MUSIC谱图，而文献[22]–[24]则使用DNN直接生成（离散化的）空间谱。然而，这些DNN辅助的估计器[21]–[24]并未训练来直接提供DoA，因此仍然共享基于模型的子空间方法的局限性。</p>
<p>​	最近有几项研究[28]-[31]提出了一种架构，在处理所得到的 MUSIC 频谱的同时，联合学习计算经验协方差。由此产生的估计器能够应对相干源和宽带源等情况。然而，这种增强以牺牲子空间方法的可解释性为代价，因为 DoAs 是通过使用额外的 DNN 从经验协方差中恢复的，学习的深度模型无法从其 MUSIC 频谱中提取有意义的解释。这就促使我们设计 DNN 辅助的 DoA 估计器，以应对基于模型的子空间方法的局限性（如相干源和较少的快照），同时保留其可解释性和适用性。</p>
<p>​	在这里，我们提出了 SubspaceNet，它利用数据来实现基于子空间的 DoA 估计。SubspaceNet 旨在应对相干源、宽带信号、快照少和校准不匹配等问题。这是因为基于模型的子空间方法依赖于接收信号的经验协方差，而基于模型的子空间方法的这些局限性正是这些局限性的体现。因此，SubspaceNet 保留了子空间方法的操作，同时使用专用的可训练自动编码器，该编码器可从数据中学习如何将观测信号的经验自相关映射到对基于子空间的 DoA 恢复普遍有用的替代协方差，即可分解为信号子空间和噪声子空间。</p>
<p>​	为了训练能产生符合子空间的协方差估计值的自动编码器，我们利用 Root-MUSIC 固有的可微分性，将该算法转换为可训练的判别模型[35]。这样，经过训练的 DNN 就能计算出有意义的子空间表示，从而得出准确的 DoA 估计值，而无需提供地面真实的可分解协方差。因此，SubspaceNet 可以学习计算有意义的子空间表示，这些子空间表示一经训练，就可以与不同的子空间 DoA 估计器相结合，包括 MUSIC、Root-MUSIC 和 ESPRIT。我们的经验表明，在相干和非相干信号源方面，SubspaceNet 的性能都优于基于模型的子空间方法，而且在宽带信号、校准不匹配、低信噪比 (SNR) 和快照较少的情况下也能成功运行。我们还证明 SubspaceNet 在噪声子空间和信号子空间之间建立了清晰而显著的区别，这有助于诊断和识别信号源的数量。</p>
<p>​	本文接下来的内容安排如下： 第二节阐述了设置并回顾了子空间方法。第三节介绍 SubspaceNet，第四节对其进行数值评估。最后，第五节对本文进行总结。</p>
<p>​	在本篇文章中，我们用大写加粗表示矩阵，例如$\textbf{X}$, 小写加粗表示向量，例如$\textbf{x}$， 然后我们将向量$\mathbf{x}$ 的第$j$ 个元素表示为$[\mathbf{x}]<em>j$ ，矩阵$\mathbf{X}$ 的第$i,j$ 个元素表示为$[\mathbf{X}]</em>{i,j}$ 。</p>
<h2 id="2-系统模型预览"><a href="#2-系统模型预览" class="headerlink" title="2.系统模型预览"></a>2.系统模型预览</h2><p>​	在本节中，我们将介绍系统模型，首先在 II-A 小节中介绍接收信号模型。然后，我们在 II-B 小节中简要回顾了基于子空间的 DoA 估计，并在 II-C 小节中提出了所考虑的问题。</p>
<h3 id="A-信号DoA估计模型"><a href="#A-信号DoA估计模型" class="headerlink" title="A. 信号DoA估计模型"></a>A. 信号DoA估计模型</h3><p>​	我们考虑一个配备有均匀线性阵列（ULA）的接收器，该阵列由$ N$ 个半波长间距的天线元件组成。在每个离散的时间实例$t$（在 $T$ 个快照的范围内，即 $t∈ {1, … , T }$），接收器收集多维观测数据，表示为 $x(t) &#x3D; [x_1(t), … , x_N (t)]∈ C^N$。这些信号来自 $M$ 个信号源，表示为 $\mathbf{s}(t) &#x3D; [s_1(t), … , s_M (t)] ∈ C^M$，这些信号源的 DoAs 以向量形式表示为 $\mathbf{θ} &#x3D; [θ_1, … , θ_M ]$。系统如图 1 所示。DoA 估计是从 $T$ 个快照中获得的观测数据中恢复 $\mathbf{\theta}$。</p>
<p>​	如果发射信号是窄带信号，且位于阵列的远场，则 $T$ 个快照的接收信号（表示为 $\mathbf{X} &#x3D; [\mathbf{x}(1), … , \mathbf{x}(T )] ∈ C^{N ×T}$）通常建模为</p>
<img src="https://cdn.jsdelivr.net/gh/Gavin-rep/Pictures@master/image-20240811132256684.png" alt="image-20240811132256684" style="zoom: 50%;" />

<p>在 (1) 中，$\mathbf{S} &#x3D; [\mathbf{s}(1), … , \mathbf{s}(T )]∈ C^{M ×T}$ 是信号源矩阵；$\mathbf{V}∈ C^{N ×T}$ 是噪声矩阵，由方差为 $σ^2_V$ 的 i.i.d 条目组成；并且$\mathbf{A}(\mathbf{θ}) &#x3D;[\mathbf{a}(θ_1), … , \mathbf{a}(θ_M )]∈ C^{N ×M}$是转向矩阵，其中</p>
<img src="https://cdn.jsdelivr.net/gh/Gavin-rep/Pictures@master/image-20240811132636916.png" alt="image-20240811132636916" style="zoom:50%;" />

<p>​	这里的源为均值为零且平稳的，从(1) 可求得观测值的协方差:</p>
<img src="https://cdn.jsdelivr.net/gh/Gavin-rep/Pictures@master/image-20240811132757266.png" alt="image-20240811132757266" style="zoom:50%;" />

<p>这里的$\mathbf{R}_s $ 表示$\mathbf{S}$ 的协方差。</p>
<h3 id="B-基于Subspace的DoA估计"><a href="#B-基于Subspace的DoA估计" class="headerlink" title="B. 基于Subspace的DoA估计"></a>B. 基于Subspace的DoA估计</h3><p>​	子空间方法是一系列 DoA 估计算法，依靠的是将 (3) 中的观测协方差矩阵分解为正交信号和噪声子空间的能力。它们基于以下假设：</p>
<ul>
<li><p>AS1  源都是窄带的， 如公式(1)所示。</p>
</li>
<li><p>AS2  源为非相干的，也就是说，在(3) 中的协方差矩阵$\mathbf{R}_S$ 是满秩的(full rank)。</p>
</li>
<li><p>AS3  阵列经过校准，因此 (2) 中的转向矢量是已知的，并与阵列精确匹配。</p>
</li>
<li><p>AS4  快照$T$ 的数量是足够大的，并且SNR也是足够高，因此可以根据经验可靠地估计(3) 中的$\mathbf{R}_X$为</p>
<img src="https://cdn.jsdelivr.net/gh/Gavin-rep/Pictures@master/image-20240811133419947.png" alt="image-20240811133419947" style="zoom:50%;" /></li>
</ul>
<p>​	在 AS1-AS3 假设条件下，子空间方法将 (3) 中的协方差矩阵 $\mathbf{R}_X$ 分解为正交子空间，在 AS4 条件下可以充分估计 。为此，我们将 $\mathbf{R}_X$ 的特征值分解（EVD）写为</p>
<img src="https://cdn.jsdelivr.net/gh/Gavin-rep/Pictures@master/image-20240811133520906.png" alt="image-20240811133520906" style="zoom:50%;" />

<p>其中，$\mathbf{Λ}$ 是对角特征值矩阵，而单元矩阵 $\mathbf{U} &#x3D; [\mathbf{u}_1, … , \mathbf{u}_N ]$ 是其对应的特征向量。由此得到的特征向量 $\mathbf{U}$ 跨过一个观测空间，该观测空间可分为两个正交子空间：信号子空间 $\mathbf{U}_S$ 和噪声子空间$ \mathbf{U}_N$ [3]，即</p>
<img src="https://cdn.jsdelivr.net/gh/Gavin-rep/Pictures@master/image-20240811133651577.png" alt="image-20240811133651577" style="zoom:50%;" />

<p>在(6)中，$\mathbf{U}_S$ 包含了$M$ 个特征向量，每个特征向量对应于一个特定的定向入射源[36]，并由转向矩阵 $\mathbf{A}(\mathbf{θ})$ 的列跨过；$(N - M ) × N$ 矩阵 $\mathbf{U}_N$ 由对应于 $\mathbf{R}<em>X$ 的 $N - M $个最小主特征值（等于 $σ^2</em> V$）的特征向量组成，表示噪声子空间。</p>
<p>​	表示 (6) 意味着 $\mathbf{A}(\mathbf{\theta})⊥\mathbf{U}_N$，从而得出</p>
<img src="https://cdn.jsdelivr.net/gh/Gavin-rep/Pictures@master/image-20240811134106987.png" alt="image-20240811134106987" style="zoom:50%;" />

<p>对于所有 $i∈1, . , M $. 等式 (7) 是子空间方法的基础，子空间方法利用等式 (7) 来识别 DoAs。</p>
<ol>
<li>MUSIC: 可以说，最常见的基于子空间的 DoA 估算器是 MUSIC [3]。在这里，(7) 是通过对噪声子空间的转向向量进行反投影来构建频谱表示。具体来说，噪声子空间矩阵和声源数量是通过经验协方差 (4) 的 EVD 分别估计为 $\hat{M}$ 和 $\hat{\mathbf{U}}_N$ 的。由此得到的 MUSIC 频谱为</li>
</ol>
<img src="https://cdn.jsdelivr.net/gh/Gavin-rep/Pictures@master/image-20240811134250730.png" alt="image-20240811134250730" style="zoom:50%;" />

<p>然后，通过识别构建的频谱$ P_{MUSIC}(θ)$的峰值来恢复 DoAs，也就是说，MUSIC 频谱提供了可解释的 DoAs 可视化表示。</p>
<ol start="2">
<li><p>Root-MUSIC: 从估算的 $\hat{\mathbf{U}}_N$ 中恢复 DoAs 的另一种方法是寻找 (7) 的根。具体而言，Root-MUSIC 使用对角线和系数 $f_n$ 来表示赫米矩阵 $\mathbf{F} &#x3D; \hat{\mathbf{U}}_N \hat{\mathbf{U}}^H_N$，其定义为</p>
<img src="https://cdn.jsdelivr.net/gh/Gavin-rep/Pictures@master/image-20240811134624833.png" alt="image-20240811134624833" style="zoom:50%;" /></li>
</ol>
<p>其中对于$n &lt; 0$ ，有$f_n &#x3D; f_{|n|}^*$ 。 将(9) 插入(7) ， 那么(7)的左边可以表示为一个$2N-2$ 阶复值参数$z$ 的多项式方程，由下式给出</p>
<img src="https://cdn.jsdelivr.net/gh/Gavin-rep/Pictures@master/image-20240811134802381.png" alt="image-20240811134802381" style="zoom:50%;" />

<p>其中$z &#x3D; e^{-j \pi sin(\theta)}$ 。 Root-MUSIC 从多项式 (10) 的根中识别出 DoAs。根图谱被视为Root-MUSIC 频谱。由于 (10) 有$ 2N - 2 &gt; M$ 个根（分为对称的对根），而 DoAs 对应的根应具有单位幅度，因此最接近单位圆的$\mathbf{\hat{M}}$ 对根被匹配为$\hat{M}$ 个 DoAs 源[4]。与 MUSIC 相似，Root-MUSIC 频谱提供了一种有意义的 DoAs 可视化方法</p>
<p><img src="https://cdn.jsdelivr.net/gh/Gavin-rep/Pictures@master/image-20240811161913738.png" alt="image-20240811161913738"></p>
<img src="https://cdn.jsdelivr.net/gh/Gavin-rep/Pictures@master/image-20240811135542936.png" alt="image-20240811135542936" style="zoom:50%;" />

<p>对于某个矩阵$\mathbf{H}$。由于 $\mathbf{H}$ 的特征值等于 $\mathbf{E}$ 的对角线元素，因此通过求解 (11)，即求解 $\mathbf{H}$，就可以从这些特征值恢复 DoAs。因此，ESPRIT 将 DoA 向量估计为 $\mathbf{\hat{\theta} &#x3D; sin^{-1}（∠eig{\mathbf{H}}&#x2F;π）}$，其中$ eig{\mathbf{H}}$ 是$\mathbf{H}$ 特征值的向量代表，∠(-) 是角度算子。</p>
<h3 id="C-问题表述"><a href="#C-问题表述" class="headerlink" title="C. 问题表述"></a>C. 问题表述</h3><p>​	子空间方法以不受物理阵列限制的角度分辨率可靠地估算出 DoAs，而且通常能提供可解释的 DoAs 可视化结果以及不确定性测量值。然而，它们对假设 AS1-AS4 的依赖在各种实际场景中可能成为限制因素，这些场景通常涉及宽带信号、相干信号源、误判、有限快照和低信噪比。我们的目标是设计一种方法，使子空间方法也能在 AS1-AS4 不成立的情况下运行。</p>
<p>​	具体而言，我们考虑从观测矩阵$\mathbf{ X}$ 中恢复 $\mathbf{\theta}$。虽然不假定 $M$ 的数量是事先已知的，但我们将注意力限制在 $M$ 小于天线元件数 $N$的情况下。同样，快照次数 $T$ 在系统设计期间也是未知的，不过它的下限是某个 $T_{min}$（可以小到一个快照）。</p>
<p>​	为了减轻对 AS1-AS4 的依赖，我们考虑了一种数据辅助设置，即我们可以获取由 $J$ 对观测数据及其相应的 DoAs 组成的数据集，表示为</p>
<img src="https://cdn.jsdelivr.net/gh/Gavin-rep/Pictures@master/image-20240811140204634.png" alt="image-20240811140204634" style="zoom:50%;" />

<p>这些数据可以来自真实世界的信号源，也可以来自与预期检测到的信号非常相似的合成数据。不同的实现可能包含不同数量的信号源 $M$ 和不同数量的快照$ T$，也就是说，$\mathbf{\theta}^{(j)}$ 的维度和$\mathbf {X}^{(j)}$ 的列数可以随样本索引 $j$ 的变化而变化。</p>
<h2 id="3-SubspaceNet"><a href="#3-SubspaceNet" class="headerlink" title="3. SubspaceNet"></a>3. SubspaceNet</h2><p>​	在本节中，我们将介绍拟议的 SubspaceNet。首先，我们将在第 III-A-III-B 小节中分别讨论该算法的高层原理及其架构。然后，我们将在第 III-C-III-D 小节中分别介绍如何训练 SubspaceNet 和在推理过程中如何应用 SubspaceNet，并在第 III-E 小节中进行讨论。</p>
<h3 id="A-高级原理"><a href="#A-高级原理" class="headerlink" title="A. 高级原理"></a>A. 高级原理</h3><p>​	假设 AS1-AS4 对子空间方法至关重要的原因在于它们在推导 (7) 中的正交相等关系时所起的作用。当这些假设不成立时，就无法可靠地获得输入协方差的估计值，无法将其分解为与信号和噪声相对应的正交子空间。基于子空间方法的敏感性包含在经验协方差计算中这一认识，我们提出了 SubspaceNet。SubspaceNet 将子空间方法与深度学习相结合，作为一种基于模型的深度学习[33]、[34]，通过提供可划分为正交信号子空间和噪声子空间的替代协方差矩阵来应对上述挑战。为此，我们采用了专门的 DNN，通过数据学习产生所需的协方差。DNN 的结构详见第 III-B 小节。然后，不同的子空间方法可以使用这种替代协方差，同时保留其操作性和可解释性，详见第 III-D 小节。</p>
<p>​	由于不存在“基本事实”代理协方差，因此无法像监督学习中常见的那样，通过将其输出与参考标签进行比较来训练 DNN。相反，我们根据 DNN 对基于子空间的 DoA 估计的有用性来评估 DNN 产生的协方差。因此，通过将（12）中可用的 DoA 与采用 DNN 的子空间 DoA 估计器输出处恢复的 DoA 进行比较来计算训练损失，从而将 DoA 估计算法转换为可训练的判别模型 [35]。由于 DNN 训练基于一阶方法，因此在训练期间处理学习到的协方差的 DoA 估计器必须是可微分的，即，应该能够计算估计的 DoA 相对于估计的协方差的梯度。与 MUSIC 的映射基于不可微的峰值查找不同，Root-MUSIC 本质上是可微的，因此用于训练 SubspaceNet，如第 III-C 小节中所述。总体高层设计如图 2 所示。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Gavin-rep/Pictures@master/image-20240811141101327.png" alt="image-20240811141101327"></p>
<h3 id="B-结构"><a href="#B-结构" class="headerlink" title="B. 结构"></a>B. 结构</h3><p>​	SubspaceNet 采用的可训练架构旨在将输入信号 $\mathbf{X}$ 映射为协方差估计值（用 $\mathbf{\hat{R}}$ 表示），而不受快照 $T$ 数量的影响。这一过程分为三个阶段：从 $\mathbf{X}$ 中提取对代理协方差估计任务有参考价值的特征；使用基于 DNN 的自动编码器处理这些特征；以及对 DNN 输出进行后处理，以获得协方差估计值。接下来，我们将详细阐述这些阶段。</p>
<ol>
<li>特征提取： 我们在设计用于计算代用协方差的特征时，借鉴了聚焦技术[37]。这些方法旨在通过将协方差估计为输入多变量功率谱密度的线性组合，将宽带 DoA 恢复设置转换为窄带恢复设置。由于静态信号的功率谱密度是通过其自相关函数的傅立叶变换得到的[38]，因此我们使用 $\mathbf{x}(t)$ 的经验自相关作为输入特征</li>
</ol>
<p>​	具体来说，我们设定最大滞后数 $τ_{max}$ &gt; 0，它不大于最小快照数 $T_{min}$。然后，对于每个 $τ∈ {0. . . , τ_{max}}$时，我们计算 $\mathbf{X}$ 的经验自相关性为</p>
<img src="https://cdn.jsdelivr.net/gh/Gavin-rep/Pictures@master/image-20240811141522194.png" alt="image-20240811141522194" style="zoom:50%;" />

<p>因此，由 DNN 处理的提取特征是一个 $N × N × (τ_{max} + 1)$ tensor，即其维度与 $T$ 无关。因此，这既能为 DNN 提供被认为对获得有用的替代协方差矩阵有参考价值的特征，又能使 DNN 不受快照数量 $T$ 的影响。</p>
<ol start="2">
<li>DNN 自动编码器： 如图 3 所示，我们利用去噪自动编码器中的 DNN 架构来处理 ${ \hat{\mathbf{R}}X[\tau] }^{\tau{\text{max}}}_{\tau &#x3D; 0}$。自动编码器是一种深度学习架构，用于从噪声数据中选择相关特征并将其映射到高维表征中[39]。DNN 的编码器部分由三个 CNN 层组成，滤波器的大小逐渐增大。其目标是将输入映射到低维潜在表示中，只保留对任务有意义的信息，从而过滤掉不必要的信息和噪音。解码器由滤波器大小逐渐减小的解卷积神经网络（DCNN）层组成，其目的是从潜特征中恢复出连续的信息细节，并通过层层递进的方式产生一个 $2N × N $矩阵，经过后处理后将其转化为代协方差。</li>
</ol>
<img src="https://cdn.jsdelivr.net/gh/Gavin-rep/Pictures@master/image-20240811141659561.png" alt="image-20240811141659561" style="zoom: 67%;" />

<p>我们使用具有 $2 × 2 $内核的 CNN 层。这种较小的内核尺寸可以捕捉到自相关输入上相邻传感器之间的局部相位相关性，并有可能提高对噪声的鲁棒性。后者是因为整个频谱的SNR不是恒定的，因此滤波器可以检测高信噪比频谱区域的局部相位结构，以弥补低信噪比区域信息的不足。与计算机视觉等领域中 CNN 自动编码器的传统用法不同，我们没有采用池化层来避免丢弃有用的空间信息。我们不使用常见的整流线性单元激活 $ReLU(z) &#x3D; max(0，z)$，而是使用反整流激活。这确保了正负值都能被激活，使其更适用于包含正负值的感知数据[40]。反整流激活表示为输入的正负两部分的并集。也就是说，$N_z \times 1$ 形状的输入向量$\mathbf{z} &#x3D; [z_1,…,z_{N_z}]^T$ ，那么激活输出一个形状为$2N_z \times1$ 的矢量有：</p>
<img src="https://cdn.jsdelivr.net/gh/Gavin-rep/Pictures@master/image-20240811142256902.png" alt="image-20240811142256902" style="zoom:50%;" />

<ol start="3">
<li>后处理： 自动编码器的输出是一个 $2N × N $的实矩阵。为了将其转换成代协方差矩阵（即 $N × N$ 复Hermitian正定矩阵），我们首先将输出重塑为复数矩阵 $\mathbf{K}∈ C^{N ×N}$，将前 $N$ 行视为实部，其余 $N$ 行视为虚部。为了计算代协方差，我们通过以下方法将 $\mathbf{K}$ 转换为HHermitian正定协方差估计值</li>
</ol>
<img src="https://cdn.jsdelivr.net/gh/Gavin-rep/Pictures@master/image-20240811143612003.png" alt="image-20240811143612003" style="zoom:50%;" />

<p>其中$\epsilon &gt; 0$ 是这个机构固定的超参数。</p>
<p>​	架构的可训练参数是自编码器的权重，用 $ψ$ 表示。因此，我们将整体映射写成 $\hat{\mathbf{R}}(\mathbf{X}; ψ)$，包括特征提取、DNN 处理和输出重塑阶段。</p>
<h3 id="C-训练"><a href="#C-训练" class="headerlink" title="C. 训练"></a>C. 训练</h3><p>​	训练过程使用数据集 D (12) 调整参数 $ψ$，使代理协方差 $\hat{\mathbf{R}}(\mathbf{X}; ψ)$ 对基于子空间的 DoA 恢复有用，即可以将其分解为包含信号和噪声的正交子空间。为了实现这一点，我们鼓励将$\hat{\mathbf{R}}(\mathbf{X}; ψ)$作为一个协方差矩阵，利用该矩阵，Root-MUSIC 所恢复的 DoA（表示为$\hat{\theta}(\hat{\mathbf{R}}(\mathbf{X}; ψ))$）就是对 $\mathbf{\theta}$的精确估计。 为了说明如何实现这一点，我们首先讨论损失度量，然后解释训练过程。</p>
<ol>
<li>损失度量：损失函数通过比较 Root-MUSIC 结合 SubspaceNet 所恢复的 DoA 来评估 DoA 估计的质量。原则上，我们可以使用回归任务的标准损失度量，例如均方误差，但在评估 DoA 恢复时，我们必须考虑以下属性：</li>
</ol>
<p>​	P1  DoAs 是周期量，即估计 $\hat{\mathbf{\theta}}+2π$ 与 $\mathbf{\hat{\theta}}$ 相同。因此，角度与其估计值之间的差值并不一定与实际误差一致。</p>
<p>​	P2  DoA 估计与预测 DoAs 的顺序无关，例如，估计 $\hat{\mathbf{\theta}}&#x3D; [\theta_1, \theta_2]^T$ 等于输出 $\hat{\mathbf{\theta}} &#x3D; [\theta_2, \theta_1]^T$ 。</p>
<p>​	P3  信号的数量 $\hat{\mathbf{M}}$ 也是估算出来的，因此可能与真实的 $M$ 有所差异，也就是说，输出的坐标可能不等于地面真实 		DoAs 的坐标。</p>
<p>​	为了考虑 P1，我们采用了均方根周期误差（RMSPE）损失法[41]，该方法评估周期范围内的元素误差。我们通过修改 RMSPE 损失来比较预测 DoAs 与真实标签的所有可能组合，从而在 P2 的基础上扩展了这一测量方法，使其具有排列不变性。为了应对 P3，我们在评估损失时，通过将最后 $M - \hat{M}$ DoAs 恢复的 $\hat{\mathbf{\theta}}$ 设为零，来处理 $\hat{M} &lt; M $的情况。</p>
<p>​	当将 Root-MUSIC 应用于来自 DoAs $\mathbf{\theta}$ 的输入 $\mathbf{X}$ 并同时考虑 P1-P3 时，所产生的损失函数用于评估SubspaceNet。其计算公式为</p>
<img src="https://cdn.jsdelivr.net/gh/Gavin-rep/Pictures@master/image-20240811145429507.png" alt="image-20240811145429507" style="zoom:50%;" />

<p>其中，$mod_π$ 表示有关角度范围的模数运算，即 $[-π&#x2F;2，π&#x2F;2]$；$P$ 是所有 $M × M $置换矩阵的集合，即每行和每列都包含一个非零条目的二进制矩阵。数据集 D 的损失计算公式为</p>
<img src="https://cdn.jsdelivr.net/gh/Gavin-rep/Pictures@master/image-20240811145516595.png" alt="image-20240811145516595" style="zoom:50%;" />

<ol start="2">
<li><p>训练程序： 之所以选择 Root-MUSIC 作为基于模型的估计器来训练 SubspaceNet，是因为其映射具有可微分性。具体来说，DoA 估计值是从多项式方程 (10) 的根中获得的，而多项式方程可以表示为隐式多项式函数。隐式微分使得计算多项式根的导数成为可能，而根式 MUSIC 中的 DoA 估计值使用的就是多项式根相对于其系数的导数${f_n}$[42]. 这些系数${f_n}$是从估计协方差矩阵的 EVD 中得到的，因此可以对其进行微分，参见文献[43]。</p>
<p>上述特性允许使用一阶方法，如随机梯度下降法（SGD）及其变体，对 SubspaceNet 的 DNN 参数进行端到端优化。特别是自动微分引擎，如 Autograd [44]，可以通过图 2a 中的 Root-MUSIC 块反向传播，计算损失 (16) 相对于可训练参数 $ψ$ 的梯度。使用 SGD 的子空间网络训练过程详见算法 1。</p>
</li>
</ol>
<img src="https://cdn.jsdelivr.net/gh/Gavin-rep/Pictures@master/image-20240811145843455.png" alt="image-20240811145843455" style="zoom:50%;" />

<h3 id="D-推理"><a href="#D-推理" class="headerlink" title="D. 推理"></a>D. 推理</h3><p>​	由于 Root-MUSIC 的可微分性，我们在训练过程中使用了 Root-MUSIC。不过，一旦训练完成，SubspaceNet 可以无缝地融入任何经典的子空间方法，如 MUSIC 和 ESPRIT，产生一个协方差矩阵，便于进行 DoA 估算，如图 2b 所示。推理算法见算法 2。这种即插即用的特点具有显著优势，因为它可以显著提高经典方法的性能，使其能够在 AS1-AS4 不成立的恶劣环境中可靠运行，即原始的基于模型（MB）算法通常会失败的地方。这要归功于学习到的代理协方差矩阵能让算法在满足 AS1-AS4 的情况下运行，因此它们能精确地区分噪声子空间和信号子空间，正如我们在第四节中演示的那样。</p>
<img src="https://cdn.jsdelivr.net/gh/Gavin-rep/Pictures@master/image-20240811150022228.png" alt="image-20240811150022228" style="zoom:50%;" />

<p>​	虽然目前对 SubspaceNet 的介绍考虑的是基于子空间的 DoA 估计，但它所学习的协方差有助于 DoA 恢复这一事实也可以被其他形式的基于协方差的方法所利用。例如，在第四节的最新研究中，我们展示了 SubspaceNet 生成的协方差可被最小方差无失真响应（MVDR）[45] 利用，后者无需将协方差分解为信号和噪声子空间即可处理协方差表示。我们证明，将 MVDR 与 SubspaceNet 结合使用，可以应对波束成形器通常难以解决的问题，例如相干信号源。</p>
<h3 id="E-讨论"><a href="#E-讨论" class="headerlink" title="E. 讨论"></a>E. 讨论</h3><p>​	所提出的子空间网络（SubspaceNet）通过使用深度学习工具来利用数据，使子空间方法能够在存在相干源、宽带信号、有限快照、误校准阵列和低信噪比的情况下可靠地运行。要做到这一点，我们需要确定应对这些挑战的难点与协方差矩阵的计算有关。因此，我们提出了一种专用的 DNN 架构，通过训练其输出来提供替代协方差，从而有助于基于 Root-MUSIC 的 DoA 恢复。由此产生的子空间网络（SubspaceNet）结合了抽象 DNN，使基于子空间的下游 DoA 恢复得以准确执行，同时保留了这些基于模型的方法的可解释性操作，例如提取有意义的频谱表示的能力，这一点在第四节中得到了一致证明。</p>
<p>​	文献[30]以 MUSIC 为重点，必须修改其操作才能进行训练，相比之下，Root-MUSIC 的继承可分性允许对架构进行端到端训练，而不会影响计算协方差的方式。SubspaceNet 经过训练后，就能让子空间方法在恶劣条件下实现精确的 DoA 估计，同时还能生成有意义的频谱，如第四章所示。这种有原则的 DNN 增强方法显著提高了基于子空间的 DoA 恢复能力。不过，在某些情况下，它也会导致复杂性和适应性方面的折衷。例如，虽然与其他数据驱动方法相比，子空间网络的复杂性明显较低 [13], [31]，但在某些有限的感知设备上实现 DNN 模块的计算量可能会很大。此外，虽然我们可以设想将其扩展到无监督操作（例如，利用信号模型中的结构 [20] 或增强算法 [46]）和跨阵列适应性（例如，通过设备学习 [47] 或使用超网络 [48]），但就其当前形式而言，SubspaceNet 是通过给定阵列的充足数据以监督方式进行训练的。</p>
<p>​	SubspaceNet 的推导考虑了 ULA 的 DoA 恢复，详见第 II-A 小节。不过，它的表述可以扩展到其他形式的阵列，包括平面阵列 [49]、环形阵列 [50] 和稀疏阵列 [51]，在这些阵列中，子空间方法被用于 DoA 恢复。对于后者，如第四节所述，子空间网络能够学习克服阵列错配，这使其极具吸引力。此外，虽然我们使用 Root-MUSIC 训练 SubspaceNet，但由于 ESPRIT 的端到端可微分性，我们也可以考虑在训练过程中使用 ESPRIT。具体来说，由于 ESPRIT 依赖于信号子空间估计（而不是噪声子空间），因此在估计大量信号源时，在训练过程中使用 ESPRIT 将大有裨益。此外，我们注意到，除了深度学习模型的传统超参数外，SubspaceNet 还引入了一个额外的超参数，即 (15) 中的$\epsilon$。在第四节的数值研究中，我们在所有设置中都保持其固定值。尽管如此，我们仍有可能认为$\epsilon$ 与 (3) 中窄带信号协方差矩阵表示中的噪声变量有关。这就促使我们探索$\epsilon$ 与信噪比相关的设置。我们将把 SubspaceNet 的这些扩展留待今后研究。</p>
<h2 id="4-数值分析"><a href="#4-数值分析" class="headerlink" title="4. 数值分析"></a>4. 数值分析</h2><p>​	在本节中，我们将对 SubspaceNet 与不同的子空间和基于协方差的估计算法一起应用时进行实证评估。我们的实验涵盖了不一定满足 AS1-AS4 假设的场景，并展示了 SubspaceNet 在保持性能和可解释性的同时，使经典 DoA 估计器在这些场景中运行的能力。我们首先在第 IV-A 小节中详细介绍实验设置，然后在第 IV-B 小节中报告在这些设置下取得的性能。最后，我们将在第 IV-C 小节中研究 SubspaceNet 与不同基于模型的方法相结合时的可解释性。</p>
<h3 id="A-实验设置"><a href="#A-实验设置" class="headerlink" title="A. 实验设置"></a>A. 实验设置</h3><ol>
<li>信号模型： 在整个研究过程中，我们考虑了一个由 $N &#x3D; 8$ 个传感器组成的 ULA，其中有 $M$ 个入射信号，我们模拟了不同的 $M$ 值。除了第 IV-B3 小节中报告的研究（我们考虑了宽带设置），信号都是根据 (1) 生成的，即代表窄带情况。DoAs 从区间 $[-\frac{\pi}{2} , \frac{\pi}{2} ]$ 中均匀生成。信噪比定义为 $SNR &#x3D; 10 log_{10} σ^2_S &#x2F;σ^2_V$，其中 $σ^2_S$ 是信源方差。</li>
<li>SubspaceNet 架构： 如第 III-B 小节所述，SubspaceNet 由 DNN 自编码器和不可训练的前处理和后处理组成。(13) 中的自相关特征是针对延迟值$\tau$提取的, 这是一个超参数（在我们的实验中通过手动调整设置），受到观测数量 $τ ≤ T − 1$的限制。所使用的自动编码器架构由三个卷积层组成，具有 16、32 和 64 个输出渠道，分别。接下来是三个反卷积层，分别具有 32、16 和 1 个输出通道。每层的内核大小设置为 2 × 2。自动编码器的输出通过 (15) 重塑为代理协方差，其中 $\epsilon&#x3D; 1$。可训练参数的总数为 $41, 761$。该架构使用Adam 优化器 [52]，学习率 $µ &#x3D; 0.001$。为了简洁起见，我们在图例中使用 SubspaceNet 的缩写术语 SubNet。</li>
<li>DoA 估算器： 为了评估 SubspaceNet 改进经典子空间方法的能力，我们对 II-B 小节中详述的经典子空间方法（即 MUSIC、Root-MUSIC 和 ESPRIT）进行了评估，比较了它们与 SubspaceNet 结合时的性能和使用标准经验协方差时的性能。具体来说，在使用 MUSIC 时，我们通过在分辨率为 $0.01$度 的网格上搜索峰值来检测频谱中的 DoAs。</li>
</ol>
<p>​	在 AS1-AS4 不成立的情况下，我们将 SubspaceNet 与经典子空间方法的代表性基于模型的扩展进行对比，以应对各种情况。特别是对于相干信号源，我们采用了 SPS 预处理，这是一种广泛采用的基于模型的方法，可用于应对此类情况 [6]、[7]。在考虑窄带非相干源时，我们还将 DoA 估计器与 [53] 中得出的相应 Ziv-Zakai 约束 (ZZB) 进行了比较。为了评估宽带设置下的 DoA 估计，我们将 SubspaceNet 与基于 [37] 中提出的技术的宽带信号模型扩展进行了比较。这包括将相关频谱划分为不同的频段，然后对每个频段分别应用经典的窄带子空间方法，并将结果汇总以得出宽带估计值。</p>
<p>​	我们还将 SubspaceNet 与其他基于 DNN 的 DoA 估算器进行了比较。我们考虑了两个数据驱动基准：1）基于 CNN 的 DoA 估算器，该估算器基于 [13] 中提出的架构，被称为 CNN，代表了一种黑盒 DNN 设计；2）[30] 中的 DA-MUSIC，它按照 MUSIC 的流程将递归神经网络和全连接架构相互连接。所有数据驱动的 DoA 估计器都在相同的数据上进行训练，这些数据由 $J &#x3D; 45000 $个样本组成，SNR 为 10 dB（除非另有说明）。在评估不同信号源数量的数据驱动型估计器时，数据由所有考虑过的 $M$ 值组成，训练后使用 8000 个 $M$ 信号源样本适应考虑过的 $M$ 值。对于 CNN 模型，与最初的论文一样，定义了分辨率为 $0.5$度 的类网格，从而产生了超过$ 21 \cdot 10^6$ 个可训练参数（分辨率越高，可训练参数的数量就越大、越密集），而 DA-MUSIC 有 $10 194$ 个可训练参数。按照 [13] 中使用的方法，为每个测试信噪比生成一个包含 $(\frac{M} {361})$ 种角度组合的数据集，从而得到一个超过 $300 000$ 个样本的广泛集合，用于训练 CNN模型。</p>
<h3 id="B-DoA-估计性能"><a href="#B-DoA-估计性能" class="headerlink" title="B. DoA 估计性能"></a>B. DoA 估计性能</h3><p>​	在此，我们通过 RMSPE 来评估 SubspaceNet 的准确性。我们考虑了相干信号源（未持有 AS2）、主要噪声和有限快照（未持有 AS4）、宽带信号（未持有 AS1）以及误校准阵列（未持有 AS3）的情况。我们通过 5000 次蒙特卡洛试验的平均值对 RMSPE 进行了经验评估。为了关注正确识别 DoAs 的能力，我们在这里将 $\hat{M}$ 设为 DoAs 的真实数量 $M$，而在第 IV-C 小节中，我们将证明 $\hat{M}$ 的确可以作为 $M$ 的准确估计值提取出来。为便于表述，比较 DoA 估计器与 SNR 的数字以 dB 为单位的均方周期误差来报告性能。</p>
<ol>
<li><p>相干源： 我们首先评估 SubspaceNet 有效处理相干源的能力。我们将重点放在具有挑战性的全相干情况上，在这种情况下，所有信号源都表现出相同的相位和振幅，从而导致 $\mathbf{R}_S$ 具有最小单位秩。我们模拟了从$ T &#x3D; 100$ 个快照估算出的不同数量的窄带相干源，信噪比为 10 dB，ULA 经过校准。</p>
<p>表 I 报告了所考虑的 DoA 预估器取得的 RMSPE 结果。从表 I 中我们可以看出，SubspaceNet 增强技术可以有效、一致地处理相干源，从而提高所有基于模型的算法的性能。值得注意的是，在 M &#x3D; 2 个源上使用 SubspaceNet 增强 Root-MUSIC 后，估计性能比传统 Root-MUSIC 提高了近 60 倍。即使使用专门的 SPS 技术来增加经验协方差秩，SPS Root-MUSIC 算法的结果也不如 SubspaceNet。我们还注意到，虽然 SubspaceNet 是用 Root-MUSIC 训练出来的，但它的代协方差也明显促进了 MUSIC 和 ESPRIT 的运行，与经典和预处理估计方法相比，这两种方法的估计性能都有所提高。此外，SubspaceNet 的性能优于数据驱动基准，同时使用的参数比 CNN 模型少得多，并与 DA-MUSIC 保持了相似的参数量级，而不会限制基于模型的 DoA 估计器的可解释性，如 IV-C 小节所示。</p>
</li>
</ol>
<img src="https://cdn.jsdelivr.net/gh/Gavin-rep/Pictures@master/image-20240811152358660.png" alt="image-20240811152358660" style="zoom: 67%;" />

<ol start="2">
<li>低信噪比和少量快照： 我们接下来评估 SubspaceNet 应对低信噪比及少量快照的能力。这些条件被认为会严重恶化基于模型的 DoA 估计。为了明确 SubspaceNet 的优势，我们首先只考虑 M &#x3D; 2 个非相干信号源的低信噪比，然后限制快照的数量，再用相干信号源替换信号源，同时系统地对比 SubspaceNet 辅助 DoA 估计器与基于模型的经典操作在每种情况下的效果。在使用多个信噪比进行的实验中，数据驱动估计器使用的训练数据是该范围内考虑的最低信噪比。</li>
</ol>
<p>​	因此，我们首先考虑信噪比在$ [-5, 0] $dB 范围内的高噪声观测。信号是非相干的，快照次数为 $T &#x3D; 200$。由于 SPS 的设计并不是为了在这种具有非相干信号源和足够快照的情况下增强子空间方法，因此我们在此不采用基于 SPS 的子空间方法。因此，我们将重点放在比较它们与传统经验协方差的操作和 SubspaceNet 提供的经验协方差。图 4 中报告的结果表明，SubspaceNet 增强功能显著提高了基于子空间的 DoA 估计器应对高噪声水平的能力。这些结果表明，SubspaceNet 不仅能减轻相干性的有害影响，还能有效提高信噪比，从而提高 DoA 估计的准确性，同时在 ZZB 所规定的可实现准确性下限的有限范围内实现性能。</p>
<img src="https://cdn.jsdelivr.net/gh/Gavin-rep/Pictures@master/image-20240811152804131.png" alt="image-20240811152804131" style="zoom:67%;" />

<p>​	接下来，我们将考虑仅使用 $T &#x3D; 2 $个快照的挑战性设置。在这里，我们将信噪比设定在 $[5, 10] $dB 的范围内。图 5 所示的 DoA 估计精度清楚地表明，在基于模型的经典方法中加入 SubspaceNet 后，即使在这些方法通常不可行的情况下（即快照数不大于源数），也能有效地处理较少的观测数据。此外，随着信噪比的增加，SubspaceNet 的性能也在不断提高，而基于模型的经典方法的估计精度却因无法处理少量快照而受到影响， 因此并没有随着SNR的增大而显著提升性能。</p>
<img src="https://cdn.jsdelivr.net/gh/Gavin-rep/Pictures@master/image-20240811152957324.png" alt="image-20240811152957324" style="zoom:67%;" />

<p>​	接下来，我们将引入相干源，评估 SubspaceNet 处理不同时满足 AS2 和 AS4 的环境的能力。我们在图 6 中比较了 SubspaceNet 与基于模型的子空间方法在低信噪比（$T &#x3D; 200 $个快照）（图 6a）和中等信噪比（仅 $T &#x3D; 20 $和$ T &#x3D; 2 $个快照）（分别为图 6b-6c ）下的增强效果。为简洁起见并避免杂乱，我们在这些图中包含了两种子空间方法–Root-MUSIC 和 ESPRIT–分别应用了常规经验协方差、SPS 和 SubspaceNet。结果表明，即使在 AS2 和 AS4 均被违反的极端情况下，SubspaceNet 的替代协方差也能可靠地进行基于子空间的 DoA 估计。这一点在表 II 中也很明显，该表报告了信噪比为 5 dB 时达到的 RMSPE 值，同时还将 SubspaceNet 与数据驱动基准进行了比较，后者的性能不如 SubspaceNet。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Gavin-rep/Pictures@master/image-20240811153210152.png" alt="image-20240811153210152"></p>
<img src="https://cdn.jsdelivr.net/gh/Gavin-rep/Pictures@master/image-20240811153353873.png" alt="image-20240811153353873" style="zoom:50%;" />

<p>​	为了进一步展示 SubspaceNet 使子空间方法能够应对有限快照的能力，我们评估了所考虑方法在不同快照数量下的 RMSPE。与图 6b-6c 一样，我们考虑了信噪比为 5 dB 时的 $M &#x3D; 2 $个相干源，并在图 7 中报告了有无 SubspaceNet 的 Root-MUSIC 和 ESPRIT 与数据驱动基准的性能比较。从图 7 中我们可以看出，结合 SubspaceNet 的子空间方法始终能提高精度，而且 SubspaceNet 还能让子空间方法在快照有限的情况下可靠运行。传统的协方差处理方法在结合更多代表相干源的快照时会达到误差底线，甚至在某些情况下可能会降低精度。</p>
<img src="https://cdn.jsdelivr.net/gh/Gavin-rep/Pictures@master/image-20240811153500348.png" alt="image-20240811153500348" style="zoom:67%;" />

<ol start="3">
<li><p>宽带设置： 到目前为止，所考虑的方案都是基于 (1) 中的窄带方案。在此，我们将评估宽带环境下的 SubspaceNet。在这种情况下，我们可以在频域中对信号模型进行表述，在频率 $ω$ 下，信号模型由以下公式给出 [37]</p>
<img src="https://cdn.jsdelivr.net/gh/Gavin-rep/Pictures@master/image-20240811153657487.png" alt="image-20240811153657487" style="zoom:50%;" /></li>
</ol>
<p>在 (1) 中，$X (ω) $和 $S(ω) $分别是 $x(t)$ 和 $s(t)$ 的离散时间多变量傅里叶变换，$V(ω)$ 是噪声，组成 $\mathbf{A}(ω, \mathbf{\theta})$ 的转向向量为</p>
<img src="https://cdn.jsdelivr.net/gh/Gavin-rep/Pictures@master/image-20240811153755309.png" alt="image-20240811153755309" style="zoom:50%;" />

<p>其中$d$ 表示 ULA 的元件间距，$c$ 为传播速度。</p>
<p>​	我们使用具有$ L $个子载波的正交频分复用（OFDM）模拟时域宽带信号，其中每个载波（表示第 $m$ 个信号的第 $l$ 个子载波，用 $s_{m,l}$ 表示）都是独立调制的，具有零均值复高斯单位方差分布。整个 OFDM 信号可表示为</p>
<img src="https://cdn.jsdelivr.net/gh/Gavin-rep/Pictures@master/image-20240811153909165.png" alt="image-20240811153909165" style="zoom:50%;" />

<p>其中，$f_s$ 是采样频率，$B_f$ 是信号带宽。获取的观测数据根据 (17) 生成，其中元素间距为最小波长的一半 $d &#x3D; c&#x2F;2B_f$。我们生成具有 $L &#x3D; 500$ 个子载波的$ M &#x3D; 2$ OFDM 信号，设置 $B_f &#x3D; 0.5 kHz$。我们测试了 50 到 1000 Hz 的各种采样率，观察信号的持续时间为 1 秒，因此快照次数为 $T &#x3D; 1&#x2F;fs$。尽管 SubspaceNet 仅在 0.2 kHz 的采样率下对观测数据进行了训练，但其性能在所有采样率下都得到了评估。</p>
<p>​	我们评估了 MUSIC、Root-MUSIC 和 ESPRIT 与 SubspaceNet 结合使用时的性能，以及使用传统经验协方差时的性能，并与文献 [37] 中提出的 MUSIC 宽带扩展（将带宽划分为 50 个独立分区）进行了比较。图 8 所示的结果既考虑了非相干源，也考虑了相干源。图 8a 所示的非相干结果表明，与窄带方法和 MUSIC 的宽带扩展相比，采用 SubspaceNet 模型能显著提高性能。即使在 fs &#x3D; 50 Hz 时，只有极少量的快照可用，SubspaceNet 也能持续可靠地估计 DoA。如图 8b 所示，当声源相干时，这些结论也同样成立。相比之下，正如预期的那样，基于子空间模型的宽带扩展在相干和宽带条件下都无法估计 DoA。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Gavin-rep/Pictures@master/image-20240811154122382.png" alt="image-20240811154122382"></p>
<p>​	为了能够数值上获取SubspaceNet的具体增益，在表 III 中，我们报告了 SubspaceNet 在 M &#x3D; 2 个相干源和采样率 fs &#x3D; 200Hz 的宽带环境下取得的 RMSPE 值。我们还包括数据驱动的 DA-MUSIC 和 CNN 基准所达到的精度。表 III 显示，SubspaceNet 使基于模型的子空间方法在宽带环境中实现了大幅提高的精度，超过了数据驱动基准，也超过了专为宽带环境设计的基于模型的方法，后者的推理过程更为复杂，因为需要对每个分区进行单独的 DoA 估算。</p>
<img src="https://cdn.jsdelivr.net/gh/Gavin-rep/Pictures@master/image-20240811154416550.png" alt="image-20240811154416550" style="zoom:67%;" />

<ol start="4">
<li><p>阵列误判： 在此，我们研究了 SubspaceNet 从数据中学习处理阵列误校准的有效性。阵列流形的校准是 DoA 估计的一个关键方面，因为不准确的校准会导致巨大的误差。我们模拟了两种形式的误校准，它们都会导致实际阵列响应偏离理想模式，从而严重影响子空间方法的性能。在这两种情况下，接收信号都由 M &#x3D; 2 个非相干信号组成。</p>
<p>在第一种情况下，模拟阵列距离误判，即每对传感器之间的间距偏离半波长的标准 ULA 配置，导致元件间距不均匀。第$ m $个位置上每对相邻传感器之间的间距为标称的半波长距离 $d$ 加上一个均匀分布的随机变量 $δ_m ∼ U (-η, η)$，其中 $η$ 是与标称间距偏差的百分比。因此，(2) 中的转向矢量会被误校准，其第 $m$ 个元素的值为</p>
</li>
</ol>
<img src="https://cdn.jsdelivr.net/gh/Gavin-rep/Pictures@master/image-20240811154603275.png" alt="image-20240811154603275" style="zoom:50%;" />

<p>​	图 9a 报告了在不同的 $η ∈ [0.025d, 0.15d]$（即与校准间距的最大偏差为 30%）值下，有 SubspaceNet 和没有 SubspaceNet 的基于子空间的 DoA 估计器获得的 RMSPE 值。图 9a 中描述的结果凸显了 SubspaceNet 处理阵列几何差异的能力，尤其是当转向矢量受到非均匀（和非标称）元素间距的影响时。相比之下，经典子空间方法严重依赖于阵列流形的标称 ULA 形式，当 $η$ 增加时，会产生非最佳估计结果。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Gavin-rep/Pictures@master/image-20240811154651306.png" alt="image-20240811154651306"></p>
<p>​	在第二种情况下，我们直接在转向矢量而非元素间距中引入误判。具体做法是在转向矢量的每个元素中添加方差为 $σ^2_{sv}$ 的零均值复高斯噪声，从而在创建子空间核心方程 (7) 时产生误差。图 9b 所示的仿真结果进一步表明，与传统的子空间方法相比，SubspaceNet 在处理因添加零均值高斯噪声而导致的转向矢量损坏时确实表现出更优越的性能，从而实现更精确的 DoA 估计。另一方面，经典子空间方法似乎对这类损坏非常敏感，随着噪声方差的增加，估计结果也会变差。此外，结果表明传统子空间和SubspaceNet之间的性能差距随着转向矢量损坏的程度而增加,对于$\sigma_{sv}^2 &#x3D; 0.75$ 和 $\eta &#x3D; 0.075d$时。这表明，SubspaceNet有可能在噪声损坏和阵列几何不匹配程度较高的场景中提供更显著的优势，使其成为在具有挑战性的环境中应用的一种有前途的解决方案。</p>
<h3 id="C-可解释性"><a href="#C-可解释性" class="headerlink" title="C. 可解释性"></a>C. 可解释性</h3><p>​	迄今为止所展示的结果系统地证明，利用 SubspaceNet 对子空间方法进行增强，可使这些经典算法在其传统限制性假设 AS1-AS4 不成立的情况下可靠运行。具体来说，SubspaceNet 输出的代理协方差矩阵能使子空间方法在各种具有挑战性的情况下以无差别的方式运行： 它可以高效地处理宽带信号；准确地解析相干信号；在快照较少和噪声水平较高的情况下可靠地运行；提高对不同形式误差的鲁棒性。这些优势源于 SubspaceNet 利用 DNN 的抽象性，从数据中学习理想的映射，即提取合适的协方差矩阵。SubspaceNet 的另一个关键优势是，它能够保留基于模型的 DoA 估计器的理想可解释操作，并在通常无法实现的情况下，提供与经典方法相关的有意义的可视化表示，这是传统基于 DNN 的解决方案所不具备的。为了展示 SubspaceNet 的这一特性，我们首先直观地展示了 SubspaceNet 区分信号子空间和噪声子空间的能力。然后，我们展示了 MUSIC 和 Root-MUSIC 与 SubspaceNet 结合后获得的频谱表示，之后，我们证明了 SubspaceNet 与基于协方差的波束成形器结合后，可以产生有意义的 Beampatterns。</p>
<ol>
<li><p>子空间分离：我们首先将 SubspaceNet 产生的归一化协方差特征值与传统的和 SPS 辅助的相干源协方差经验估计进行比较。图 10 所示的结果表明，SubspaceNet 在信号子空间的 M &#x3D; 3 个主要特征值和与噪声相关的特征值之间产生了清晰的分离。相比之下，传统的经验估计只能识别与信号子空间相关的一个特征值，而SPS经验估计方法只能识别两个特征值，其余特征值归因于噪声子空间。与基于模型的子空间方法相比，SubspaceNet 区分两个子空间的能力显着增强了解析相干源的能力。 </p>
<img src="https://cdn.jsdelivr.net/gh/Gavin-rep/Pictures@master/image-20240811155430562.png" alt="image-20240811155430562" style="zoom:67%;" />
</li>
<li><p>频谱展示： 当假设AS1到AS4成立时，子空间方法展示了与真实DoA密切相关的信息丰富的频谱表示。具体来说，MUSIC 谱在 DoA 角度处显示出明显的峰值，而 Root-MUSIC 极谱则显示与单位圆上的 DoA 位置相对应的根和特征值。接下来，我们在以下违反 AS1-AS4 的场景中研究每种子空间方法及其 SubspaceNet 增强的谱行为：</p>
<ol>
<li><p>对窄带相干源的 DoA 估计，即 AS2 不成立。DoA 位于 $θ &#x3D; [-12.34\degree, 34.56\degree, 65.78\degree]$，通过 $T &#x3D; 100$ 次 SNR 为 10 dB 的快照进行观测。所得到的 MUSIC 和 Root-MUSIC 频谱如图 11 所示。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Gavin-rep/Pictures@master/image-20240811160051566.png" alt="image-20240811160051566"></p>
</li>
<li><p>AS2 和 AS4 不成立的情况，使用与表 II 中报告的研究相同的设置，声源位于 θ &#x3D; [23.45◦, 56.78◦]。产生的 MUSIC 和 Root-MUSIC 频谱如图 12 所示。<img src="https://cdn.jsdelivr.net/gh/Gavin-rep/Pictures@master/image-20240811160159515-20240811160220640.png"></p>
</li>
<li><p>根据 T &#x3D; 50 个快照对位于 θ &#x3D; [-45.67◦, -23.45◦]的宽带相干源的 DoA 估计。如图 13 所示，这里基于模型的频谱已经不能代表真实的 DoA。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Gavin-rep/Pictures@master/image-20240811160341398.png" alt="image-20240811160341398"></p>
</li>
</ol>
</li>
</ol>
<p>​	我们在图中观察到。如图 11-13 所示，SubspaceNet 生成可解释且信息丰富的频谱。 SubspaceNet+Root-MUSIC 频谱（图 11c-13c）中最接近单位圆的根以及SubspaceNet+MUSIC 频谱（图 11a-13a）可以轻松链接到实际的 DoA。另一方面，经典的 MUSIC 和 Root-MUSIC 算法无法产生有意义的频谱表示。虽然窄带相干源的 MUSIC 频谱（图 11a）可能会揭示源角度附近的小峰值，但它严重无法为图 11a 和 11a 所示的场景提供任何有意义的信息。图12a-13a。此外，SubspaceNet 还可以提供更具区分性的频谱。如图所示。如图11c-13c所示，非DoA根被推离单位圆更远，有利于它们与真正的DoA根的区分。由此产生的根音乐频谱变得更容易解释，特别是在具有挑战性的场景中。在图 12c 中的少量快照场景中可以清楚地观察到这一点，其中接近真实 DoA 的非 DoA 根（θ &#x3D; 28.4°）被从单位圆推出（|root| &gt; 8 ），防止错误分类。</p>
<ol start="3">
<li><p>波束成形模式： 最后，我们将证明 SubspaceNet 产生的代理协方差不仅适用于子空间方法，也适用于其他形式的基于协方差的阵列处理算法。为了举例说明这一点，我们考虑 MVDR [45]，这是一种流行的波束形成方法，可在抑制噪声和干扰的同时增强所需方向的信号功率。这就产生了一种能提供有关信号源方向的有价值信息的波束模式。虽然 MVDR 不依赖子空间分解来进行波束成形操作，但它采用协方差矩阵来塑造其模式，因此与经典的子空间方法一样受到经验估计的限制，其有效性仍然受到协方差矩阵估计精度的限制。</p>
<p>为了表明 SubspaceNet 促进 MVDR 的操作，我们在图 14 中可视化了使用和不使用 SubspaceNet 增强的 MVDR 实现的波束图，其设置与第 IV-C2 节中使用的设置相同。图 14 中描绘的波束方向图清楚地证明了 SubspaceNet 在生成代理协方差矩阵方面的优越性，该矩阵不仅可用于 DoA 估计子空间方法，而且还可用于获得高分辨率有效波束方向图。具体来说，无花果。图14a-14b展示了SubspaceNet在源的方向上产生窄波瓣，增强了源之间的辨别力，并且通过降低非DoA方向上的功率来减轻干扰。当使用传统的经验协方差时，MVDR 在具有多个相干源和低 SNR 的场景中实现这些目标时表现出局限性。此外，与子空间方法一样，MVDR 处理宽带源的能力本质上受到限制。这一缺点导致波束方向图明显偏离真实的 DoA，如图 14c 所示。尽管如此，通过集成 SubspaceNet 增强功能，所需方向上的接收信号功率被放大，从而增强了具有宽带和相干特性的信号的波束成形的有效性。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Gavin-rep/Pictures@master/image-20240811160852802.png" alt="image-20240811160852802"></p>
</li>
</ol>
<h2 id="5-结论"><a href="#5-结论" class="headerlink" title="5.结论"></a>5.结论</h2><p>​	我们提出了 SubspaceNet，它能够在具有挑战性的环境中进行基于子空间的 DoA 估算，在这种环境中，将阵列输入可靠地划分为信号和噪声子空间通常是不可行的。SubspaceNet 是利用深度学习工具增强子空间方法而设计的，特别是通过将 Root-MUSIC 识别为合适的可微分方法并将其转换为可训练架构，训练其生成对基于子空间的 DoA 估计普遍有用的替代协方差。SubspaceNet 利用数据学会将观测结果划分为信号子空间和噪声子空间。我们的研究结果表明，它能够成功应对相干源、宽带信号、快照少、信噪比低和阵列误判等问题，同时保留了基于模型的子空间方法的可解释性，并促进了 MVDR 等其他基于协方差的算法的运行。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="http://example.com">Gavin</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://example.com/2024/08/10/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%EF%BC%9ASubspaceNet%EF%BC%9ADeep%20Learning-Aided%20Subspace%20Methods%20for%20DoA%20Estimation/">http://example.com/2024/08/10/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%EF%BC%9ASubspaceNet%EF%BC%9ADeep%20Learning-Aided%20Subspace%20Methods%20for%20DoA%20Estimation/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://example.com" target="_blank">Gavin</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><a class="post-meta__tags" href="/tags/%E5%BC%80%E6%BA%90%E4%BB%A3%E7%A0%81/">开源代码</a><a class="post-meta__tags" href="/tags/DoA/">DoA</a></div><div class="post_share"><div class="social-share" data-image="https://i.ibb.co/HNzMHrZ/image.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="next-post pull-full"><a href="/2024/07/13/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%EF%BC%9A%20Analysis%20and%20control%20of%20multi-zone%20sound%20field%20reproduction%20using%20modal-domain%20approach/" title="文献阅读:Analysis and control of multi-zone sound field reproduction using modal-domain approach"><img class="cover" src="https://i.ibb.co/z2zkhRs/image.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">文献阅读:Analysis and control of multi-zone sound field reproduction using modal-domain approach</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2024/05/06/%20%20%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB-%20Real-time%20implementation%20and%20explainable%20AI%20analysis%20of%20delayless%20CNN-based%20selective%20fixed-filter%20active%20noise%20control/" title="文献阅读: Real-time implementation and explainable AI analysis of delayless CNN-based selective fixed-filter active noise control"><img class="cover" src="https://i.ibb.co/rk6B9g0/image.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-05-06</div><div class="title">文献阅读: Real-time implementation and explainable AI analysis of delayless CNN-based selective fixed-filter active noise control</div></div></a></div><div><a href="/2024/05/06/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%EF%BC%9A%20Transferable%20Latent%20of%20CNN-Based%20Selective%20Fixed-Filter%20Active%20Noise%20Control/" title="文献阅读: Transferable Latent of CNN-Based Selective Fixed-Filter Active Noise Control"><img class="cover" src="https://i.ibb.co/xSTFTsh/image.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-05-06</div><div class="title">文献阅读: Transferable Latent of CNN-Based Selective Fixed-Filter Active Noise Control</div></div></a></div><div><a href="/2024/05/05/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%EF%BC%9ADEEP%20GENERATIVE%20FIXED-FILTER%20ACTIVE%20NOISE%20CONTROL/" title="文献阅读: DEEP GENERATIVE FIXED-FILTER ACTIVE NOISE CONTROL"><img class="cover" src="https://i.ibb.co/LSLjfkw/image.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-05-05</div><div class="title">文献阅读: DEEP GENERATIVE FIXED-FILTER ACTIVE NOISE CONTROL</div></div></a></div><div><a href="/2024/04/23/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%EF%BC%9AA%20Hybrid%20SFANC-FxNLMS%20Algorithm%20for%20Active%20Noise%20Control%20based%20on%20Deep%20Learning/" title="文献阅读: A Hybrid SFANC-FxNLMS Algorithm for Active Noise Control based on Deep Learning"><img class="cover" src="https://i.ibb.co/5GmwJBS/image.png	" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-04-23</div><div class="title">文献阅读: A Hybrid SFANC-FxNLMS Algorithm for Active Noise Control based on Deep Learning</div></div></a></div><div><a href="/2023/10/27/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%EF%BC%9A%20Deep%20Networks%20for%20Direction-of-Arrival%20Estimation%20in%20Low%20SNR/" title="文献阅读: Deep Networks for Direction-of-Arrival Estimation in Low SNR"><img class="cover" src="https://i.ibb.co/vHV5BKD/image.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-10-27</div><div class="title">文献阅读: Deep Networks for Direction-of-Arrival Estimation in Low SNR</div></div></a></div><div><a href="/2023/10/25/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%EF%BC%9ADeep%20learning%20assisted%20sound%20source%20localization%20using%20two%20orthogonal%20first-order%20differential%20microphone%20arrays/" title="文献阅读: Deep learning assisted sound source localization using two orthogonal first-order differential microphone arrays"><img class="cover" src="https://i.ibb.co/XVMYNX3/image.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-10-25</div><div class="title">文献阅读: Deep learning assisted sound source localization using two orthogonal first-order differential microphone arrays</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://i.ibb.co/ch2RrDp/20230822001522.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Gavin</div><div class="author-info__description">我的过去常常追赶着我</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">32</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">14</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">3</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/alexandergwm"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/alexandergwm" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:wenmiaogao@163.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">May you stay young forever, do the thing in your own zone.</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%91%98%E8%A6%81"><span class="toc-number">1.</span> <span class="toc-text">摘要</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E4%BB%8B%E7%BB%8D"><span class="toc-number">2.</span> <span class="toc-text">1. 介绍</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E7%B3%BB%E7%BB%9F%E6%A8%A1%E5%9E%8B%E9%A2%84%E8%A7%88"><span class="toc-number">3.</span> <span class="toc-text">2.系统模型预览</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#A-%E4%BF%A1%E5%8F%B7DoA%E4%BC%B0%E8%AE%A1%E6%A8%A1%E5%9E%8B"><span class="toc-number">3.1.</span> <span class="toc-text">A. 信号DoA估计模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#B-%E5%9F%BA%E4%BA%8ESubspace%E7%9A%84DoA%E4%BC%B0%E8%AE%A1"><span class="toc-number">3.2.</span> <span class="toc-text">B. 基于Subspace的DoA估计</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#C-%E9%97%AE%E9%A2%98%E8%A1%A8%E8%BF%B0"><span class="toc-number">3.3.</span> <span class="toc-text">C. 问题表述</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-SubspaceNet"><span class="toc-number">4.</span> <span class="toc-text">3. SubspaceNet</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#A-%E9%AB%98%E7%BA%A7%E5%8E%9F%E7%90%86"><span class="toc-number">4.1.</span> <span class="toc-text">A. 高级原理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#B-%E7%BB%93%E6%9E%84"><span class="toc-number">4.2.</span> <span class="toc-text">B. 结构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#C-%E8%AE%AD%E7%BB%83"><span class="toc-number">4.3.</span> <span class="toc-text">C. 训练</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#D-%E6%8E%A8%E7%90%86"><span class="toc-number">4.4.</span> <span class="toc-text">D. 推理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#E-%E8%AE%A8%E8%AE%BA"><span class="toc-number">4.5.</span> <span class="toc-text">E. 讨论</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90"><span class="toc-number">5.</span> <span class="toc-text">4. 数值分析</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#A-%E5%AE%9E%E9%AA%8C%E8%AE%BE%E7%BD%AE"><span class="toc-number">5.1.</span> <span class="toc-text">A. 实验设置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#B-DoA-%E4%BC%B0%E8%AE%A1%E6%80%A7%E8%83%BD"><span class="toc-number">5.2.</span> <span class="toc-text">B. DoA 估计性能</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#C-%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%80%A7"><span class="toc-number">5.3.</span> <span class="toc-text">C. 可解释性</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-%E7%BB%93%E8%AE%BA"><span class="toc-number">6.</span> <span class="toc-text">5.结论</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2024/08/10/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%EF%BC%9ASubspaceNet%EF%BC%9ADeep%20Learning-Aided%20Subspace%20Methods%20for%20DoA%20Estimation/" title="文献阅读: SubspaceNet: Deep Learning-Aided Subspace Methods for DoA Estimation"><img src="https://i.ibb.co/HNzMHrZ/image.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="文献阅读: SubspaceNet: Deep Learning-Aided Subspace Methods for DoA Estimation"/></a><div class="content"><a class="title" href="/2024/08/10/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%EF%BC%9ASubspaceNet%EF%BC%9ADeep%20Learning-Aided%20Subspace%20Methods%20for%20DoA%20Estimation/" title="文献阅读: SubspaceNet: Deep Learning-Aided Subspace Methods for DoA Estimation">文献阅读: SubspaceNet: Deep Learning-Aided Subspace Methods for DoA Estimation</a><time datetime="2024-08-10T12:41:16.825Z" title="发表于 2024-08-10 20:41:16">2024-08-10</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/07/13/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%EF%BC%9A%20Analysis%20and%20control%20of%20multi-zone%20sound%20field%20reproduction%20using%20modal-domain%20approach/" title="文献阅读:Analysis and control of multi-zone sound field reproduction using modal-domain approach"><img src="https://i.ibb.co/z2zkhRs/image.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="文献阅读:Analysis and control of multi-zone sound field reproduction using modal-domain approach"/></a><div class="content"><a class="title" href="/2024/07/13/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%EF%BC%9A%20Analysis%20and%20control%20of%20multi-zone%20sound%20field%20reproduction%20using%20modal-domain%20approach/" title="文献阅读:Analysis and control of multi-zone sound field reproduction using modal-domain approach">文献阅读:Analysis and control of multi-zone sound field reproduction using modal-domain approach</a><time datetime="2024-07-13T02:24:11.877Z" title="发表于 2024-07-13 10:24:11">2024-07-13</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/07/03/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%EF%BC%9AGFANC-Kalman-%20Generative%20Fixed-Filter%20Active%20%20Noise%20Control%20With%20CNN-Kalman%20Filtering/" title="文献阅读: GFANC-Kalman: Generative Fixed-Filter Active  Noise Control With CNN-Kalman Filtering"><img src="https://i.ibb.co/VQ54Jw6/image.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="文献阅读: GFANC-Kalman: Generative Fixed-Filter Active  Noise Control With CNN-Kalman Filtering"/></a><div class="content"><a class="title" href="/2024/07/03/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%EF%BC%9AGFANC-Kalman-%20Generative%20Fixed-Filter%20Active%20%20Noise%20Control%20With%20CNN-Kalman%20Filtering/" title="文献阅读: GFANC-Kalman: Generative Fixed-Filter Active  Noise Control With CNN-Kalman Filtering">文献阅读: GFANC-Kalman: Generative Fixed-Filter Active  Noise Control With CNN-Kalman Filtering</a><time datetime="2024-07-03T13:30:55.710Z" title="发表于 2024-07-03 21:30:55">2024-07-03</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/06/15/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%EF%BC%9AMaximization%20of%20acoustic%20energy%20difference%20between%20two%20spaces/" title="文献阅读: Maximization of acoustic energy difference between two spaces"><img src="https://i.ibb.co/Sd650ms/image.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="文献阅读: Maximization of acoustic energy difference between two spaces"/></a><div class="content"><a class="title" href="/2024/06/15/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%EF%BC%9AMaximization%20of%20acoustic%20energy%20difference%20between%20two%20spaces/" title="文献阅读: Maximization of acoustic energy difference between two spaces">文献阅读: Maximization of acoustic energy difference between two spaces</a><time datetime="2024-06-15T06:24:10.886Z" title="发表于 2024-06-15 14:24:10">2024-06-15</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/05/06/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%EF%BC%9A%20Transferable%20Latent%20of%20CNN-Based%20Selective%20Fixed-Filter%20Active%20Noise%20Control/" title="文献阅读: Transferable Latent of CNN-Based Selective Fixed-Filter Active Noise Control"><img src="https://i.ibb.co/xSTFTsh/image.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="文献阅读: Transferable Latent of CNN-Based Selective Fixed-Filter Active Noise Control"/></a><div class="content"><a class="title" href="/2024/05/06/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%EF%BC%9A%20Transferable%20Latent%20of%20CNN-Based%20Selective%20Fixed-Filter%20Active%20Noise%20Control/" title="文献阅读: Transferable Latent of CNN-Based Selective Fixed-Filter Active Noise Control">文献阅读: Transferable Latent of CNN-Based Selective Fixed-Filter Active Noise Control</a><time datetime="2024-05-06T12:48:52.939Z" title="发表于 2024-05-06 20:48:52">2024-05-06</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2024 By Gavin</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">Have a nice day!</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, '']
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typesetPromise()
}</script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex/dist/contrib/copy-tex.min.js"></script><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', { class: 'katex-wrap'})
  })
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>