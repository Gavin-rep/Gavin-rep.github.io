<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>文献阅读: A Hybrid DSP/Deep Learning Approach to  Real-Time Full-Band Speech Enhancement | Gavin</title><meta name="author" content="Gavin"><meta name="copyright" content="Gavin"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Arxiv  31 May 2018 代码：https:&#x2F;&#x2F;github.com&#x2F;xiph&#x2F;rnnoise 摘要尽管噪声抑制在信号处理领域已相当成熟，但仍然高度依赖于估计算法和参数的精细调整。在本文中，我们展示了一种混合DSP&#x2F;深度学习的噪声抑制方法。我们着重保持尽可能低的复杂度，同时仍能实现高质量的增强语音。采用具有四个隐藏层的深度递归神经网络来估计理想的临界频带增益，同时使用更传统的">
<meta property="og:type" content="article">
<meta property="og:title" content="文献阅读: A Hybrid DSP&#x2F;Deep Learning Approach to  Real-Time Full-Band Speech Enhancement">
<meta property="og:url" content="http://example.com/2024/12/15/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%EF%BC%9AA%20Hybrid%20DSP:Deep%20Learning%20Approach%20to%20%20Real-Time%20Full-Band%20Speech%20Enhancement/index.html">
<meta property="og:site_name" content="Gavin">
<meta property="og:description" content="Arxiv  31 May 2018 代码：https:&#x2F;&#x2F;github.com&#x2F;xiph&#x2F;rnnoise 摘要尽管噪声抑制在信号处理领域已相当成熟，但仍然高度依赖于估计算法和参数的精细调整。在本文中，我们展示了一种混合DSP&#x2F;深度学习的噪声抑制方法。我们着重保持尽可能低的复杂度，同时仍能实现高质量的增强语音。采用具有四个隐藏层的深度递归神经网络来估计理想的临界频带增益，同时使用更传统的">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://i.ibb.co/VYX8yFsD/image.png">
<meta property="article:published_time" content="2024-12-15T04:12:53.312Z">
<meta property="article:modified_time" content="2025-02-25T14:32:22.737Z">
<meta property="article:author" content="Gavin">
<meta property="article:tag" content="开源代码">
<meta property="article:tag" content="语音增强">
<meta property="article:tag" content="降噪">
<meta property="article:tag" content="实时">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://i.ibb.co/VYX8yFsD/image.png"><link rel="shortcut icon" href="https://i.ibb.co/3BGBwps/2c8b98a62fbc3615.png"><link rel="canonical" href="http://example.com/2024/12/15/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%EF%BC%9AA%20Hybrid%20DSP:Deep%20Learning%20Approach%20to%20%20Real-Time%20Full-Band%20Speech%20Enhancement/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '文献阅读: A Hybrid DSP/Deep Learning Approach to  Real-Time Full-Band Speech Enhancement',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2025-02-25 22:32:22'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://i.ibb.co/0fP2mb0/image.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">30</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">19</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">3</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://i.ibb.co/VYX8yFsD/image.png')"><nav id="nav"><span id="blog-info"><a href="/" title="Gavin"><img class="site-icon" src="https://i.ibb.co/3BGBwps/2c8b98a62fbc3615.png"/><span class="site-name">Gavin</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">文献阅读: A Hybrid DSP/Deep Learning Approach to  Real-Time Full-Band Speech Enhancement</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-12-15T04:12:53.312Z" title="发表于 2024-12-15 12:12:53">2024-12-15</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-02-25T14:32:22.737Z" title="更新于 2025-02-25 22:32:22">2025-02-25</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB/">文献阅读</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="文献阅读: A Hybrid DSP/Deep Learning Approach to  Real-Time Full-Band Speech Enhancement"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>Arxiv  31 May 2018</p>
<p>代码：<a target="_blank" rel="noopener" href="https://github.com/xiph/rnnoise">https://github.com/xiph/rnnoise</a></p>
<h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>尽管噪声抑制在信号处理领域已相当成熟，但仍然高度依赖于估计算法和参数的精细调整。在本文中，我们展示了一种混合DSP&#x2F;深度学习的噪声抑制方法。我们着重保持尽可能低的复杂度，同时仍能实现高质量的增强语音。采用具有四个隐藏层的深度递归神经网络来估计理想的临界频带增益，同时使用更传统的音调滤波器来衰减音调谐波之间的噪声。该方法比传统的最小均方误差谱估计算法实现了显著更高的语音质量，同时将复杂度控制在低功耗CPU上以48 kHz实时运行的水平。</p>
<p>索引项- noise suppression, recurrent neural network</p>
<h2 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1.介绍"></a>1.介绍</h2><p>​	噪声抑制自20世纪70年代以来一直是一个研究热点。尽管在质量上取得了显著进展，但其高层结构基本保持不变。某种形式的谱估计技术依赖于噪声谱估计器，该估计器本身由语音活动检测器（VAD）或类似算法驱动，如图1所示。三个组件中的每一个都需要精确的估计器，并且难以调优。例如，最初粗糙的噪声估计器和基于谱减法的谱估计器[1]已经被更精确的噪声估计器[2]、[3]和谱振幅估计器[4]所取代。尽管取得了进展，这些估计器仍然难以设计，并且需要大量手动调优。因此，近年来深度学习技术在噪声抑制中的应用引起了广泛关注。深度学习技术已经被用于噪声抑制[5]、[6]、[7]、[8]、[9]。许多提出的方法针对的是自动语音识别（ASR）应用，在这些应用中并不要求低延迟。此外，在许多情况下，神经网络的庞大规模使得没有GPU的实时实现变得困难。在提出的方法中，我们专注于实时应用（如视频会议）并保持低复杂度。我们还关注全频带（48 kHz）语音。为了实现这些目标，我们选择了一种混合方法（第二节），其中依赖于经过验证的信号处理技术，并使用深度学习（第三节）来替代传统上难以正确调优的估计器。该方法与所谓的端到端系统有所不同，后者将大多数或所有信号处理操作替换为机器学习。这些端到端系统清楚地展示了深度学习的能力，但通常伴随着显著增加的复杂度。</p>
<img src="https://cdn.jsdelivr.net/gh/Gavin-rep/Pictures@master/image-20250225214509312.png" alt="image-20250225214509312" style="zoom: 67%;" />

<p>​	我们表明，所提出的方法具有可接受的复杂性（第 IV 节），并且它比更传统的方法（第 V 节）提供了更好的质量。我们在第 VI 节中总结了进一步改进这种方法的指示。</p>
<h2 id="2-信号模型"><a href="#2-信号模型" class="headerlink" title="2.信号模型"></a>2.信号模型</h2><p>​	我们提出了一种混合噪声抑制方法。目标是将深度学习用于需要仔细调整的噪声抑制方面，同时对不需要仔细调整的部件使用基本信号处理构建块。</p>
<p>​	主处理循环基于 20 ms 窗口，具有 50% 的重叠（10 ms 偏移）。Analysis和Synthesis都使用相同的 Vorbis 窗口 [10]，这满足 PrincenBradley 准则 [11]。该窗口定义为</p>
<img src="https://cdn.jsdelivr.net/gh/Gavin-rep/Pictures@master/image-20250225214753943.png" alt="image-20250225214753943" style="zoom:50%;" />

<p>其中$N$ 是窗长。</p>
<p>​	系统的信号级框图如图 2 所示。大部分抑制是使用从递归神经网络 （RNN） 计算的增益在低分辨率频谱包络上执行的。这些增益只是理想比率掩码 （IRM） 的平方根。更精细的抑制步骤使用音高梳滤波器衰减音高谐波之间的噪声。</p>
<img src="https://cdn.jsdelivr.net/gh/Gavin-rep/Pictures@master/image-20250225214858876.png" alt="image-20250225214858876" style="zoom:67%;" />

<h3 id="A-Band-Structure"><a href="#A-Band-Structure" class="headerlink" title="A. Band Structure"></a>A. Band Structure</h3><p>​	在[5]中采用的方法中，神经网络被用来直接估计频率分量的幅度，处理8 kHz语音时需要总共6144个隐藏单元和接近1000万个权重。如果使用20ms帧将其扩展到48 kHz语音，网络将需要400个输出（0到20 kHz），这显然会导致比我们可以承受的更高的复杂度。</p>
<p>​	避免这个问题的一种方法是假设语音和噪声的谱包络足够平坦，从而使用比频率分量更粗的分辨率。另外，我们不是直接估计谱幅度，而是估计理想的临界频带增益，这具有一个显著的优点，即其值限制在0和1之间。我们选择将频谱划分为与Opus codec[13]使用的Bark Scale[12]相同的近似。这就是说，在高频时，频带遵循Bark Scale，但在低频时每个频带至少有4个bins。我们使用的是三角形频带，而不是矩形频带，其峰值响应位于频带的边界处。这样，总共会有22个频带。因此，我们的网络只需要22个输出值，范围在[0, 1]之间。</p>
<p>​	设$w_b(k)$为频率$k$下频带$b$的幅度，我们有$∑_b w_b(k) &#x3D; 1$。对于变换后的信号$X(k)$，某个频带内的能量由此给出。</p>
<img src="https://cdn.jsdelivr.net/gh/Gavin-rep/Pictures@master/image-20250225215249414.png" alt="image-20250225215249414" style="zoom:50%;" />

<p>每个频带的增益定义为$g_b$</p>
<img src="https://cdn.jsdelivr.net/gh/Gavin-rep/Pictures@master/image-20250225215318548.png" alt="image-20250225215318548" style="zoom:50%;" />

<p>其中$E_s(b)$ 是干净语音信号(ground truth)的能量，$E_x(b)$ 是输入带噪(noisy)语音信号的能量。考虑一个理想的band增益$\hat{g}_b$ ，以下插值增益应用于每个频率bin $k$：</p>
<img src="https://cdn.jsdelivr.net/gh/Gavin-rep/Pictures@master/image-20250225215526099.png" alt="image-20250225215526099" style="zoom:50%;" />

<h3 id="B-Pitch-filtering"><a href="#B-Pitch-filtering" class="headerlink" title="B. Pitch filtering"></a>B. Pitch filtering</h3><p>​	使用基于Bark尺度的频带来计算增益的主要缺点是我们无法模拟频谱中的更细节部分。实际上，这会阻止在音调谐波之间进行噪声抑制。作为替代方案，我们可以使用梳状滤波器，在音调周期内消除音调间的噪声，类似于语音codec后处理滤波器的工作原理[14]。由于语音信号的周期性与频率密切相关（特别是在48 kHz采样率下），pitch filter在频域中基于每个频带的滤波系数$α_b$进行操作。设$P(k)$为pitch-delayed信号$x(n − T)$的加窗DFT，滤波通过计算$X(k) + α_bP(k)$进行，然后对结果信号进行重新归一化，使每个频带的能量与原始信号$X(k)$相同。</p>
<p>​	频段 $b$ 的pitch correlation定义为</p>
<img src="https://cdn.jsdelivr.net/gh/Gavin-rep/Pictures@master/image-20250225215837808.png" alt="image-20250225215837808" style="zoom:50%;" />

<p>其中$R[\cdot]$ 定义为复数的实部。请注意，对于单个频段，（5） 相当于时域音高相关性。</p>
<p>​	导出滤波系数 $α_b$ 的最优值是困难的，而最小化均方误差的值在感知上并不一定是最佳的。因此，我们基于以下约束和观察结果采用了一种启发式方法。由于噪声会导致音调相关性降低，我们通常不希望 $p_b$ 大于 $g_b$，因此对于任何满足 $p_b ≥ g_b$ 的频带，我们设定 $α_b &#x3D; 1$。当没有噪声时，我们不希望信号受到失真，因此当 $g_b &#x3D; 1$ 时，我们设定 $α_b &#x3D; 0$。同样地，当 $p_b &#x3D; 0$ 时，我们没有可增强的音调，因此设定 $α_b &#x3D; 0$。采用以下表达式计算滤波系数，可以满足所有这些约束，并在它们之间保持平滑过渡：</p>
<img src="https://cdn.jsdelivr.net/gh/Gavin-rep/Pictures@master/image-20250225220446169.png" alt="image-20250225220446169" style="zoom:50%;" />

<p>​	 尽管这里我们使用的是FIR音调滤波器，但也可以基于IIR音调滤波器计算$P(k)$，其形式为$H(z) &#x3D; \frac{1}{1 - \beta z^{-T}}$ 。这种方法在谐波之间提供了更强的衰减，但代价是会带来轻微的失真增加。</p>
<h3 id="C-特征提取"><a href="#C-特征提取" class="headerlink" title="C. 特征提取"></a>C. 特征提取</h3><p>​	网络的输入只包含基于与输出相同频带的噪声信号对数谱是有意义的。为了改善训练数据的条件，我们对对数谱应用离散余弦变换（DCT），得到22个Bark频率倒谱系数（BFCC）。除了这些系数外，我们还包括了前6个BFCC的时间导数和二阶时间导数。由于我们已经需要计算公式（5）中的音调，我们计算了跨频带的音调相关性的DCT，并将前6个系数包含在我们的特征集中。最后，我们还包括了音调周期以及可以帮助语音检测的谱非平稳性度量。总的来说，我们使用42个输入特征。与语音识别中通常使用的特征不同，这些特征不使用倒谱均值归一化，并且包括了第一个倒谱系数。这个选择是有意为之，因为我们需要追踪噪声的绝对水平，但它确实使得特征对信号的绝对幅度和通道频率响应敏感。这个问题将在第三节A部分中讨论。</p>
<h2 id="3-深度学习结构"><a href="#3-深度学习结构" class="headerlink" title="3. 深度学习结构"></a>3. 深度学习结构</h2><p>​	神经网络的结构与传统的噪声抑制算法密切相似，如图3所示。该设计基于以下假设：三个递归层分别负责图1中的三个基本组件。当然，实际上神经网络可以偏离这一假设（并且可能在某种程度上确实会偏离）。该网络共有215个单元，4个隐藏层，最大层有96个单元。我们发现增加单元数并不会显著改善噪声抑制的质量。然而，损失函数和训练数据的构造方式对最终质量有很大影响。我们发现，门控递归单元（GRU）[15]在此任务上略微优于LSTM，同时也更简单。</p>
<p>​	尽管这并非严格必要，网络中仍包含了一个VAD输出。额外的复杂度成本非常小（增加了24个权重），并且通过确保相应的GRU能够区分语音和噪声，从而改善了训练过程。</p>
<img src="https://cdn.jsdelivr.net/gh/Gavin-rep/Pictures@master/image-20250225221215373.png" alt="image-20250225221215373" style="zoom:50%;" />

<h3 id="A-训练数据"><a href="#A-训练数据" class="headerlink" title="A. 训练数据"></a>A. 训练数据</h3><p>​	由于增益的真实值需要同时包含噪声语音和干净语音，因此训练数据必须通过向干净语音数据中添加噪声来人工构造。对于语音数据，我们使用McGill TSP语音数据库（法语和英语）和NTT多语种语音数据库1（包含21种语言）。噪声来源包括计算机风扇、办公室、喧嚣、人群、飞机、汽车、火车和施工等。噪声以不同的水平混合，以产生广泛的信噪比范围，包括清晰语音和仅有噪声的片段。</p>
<p>​	由于我们不使用倒谱均值归一化，我们使用数据增强来使网络对频率响应的变化具有鲁棒性。这是通过对每个训练样本分别使用二阶滤波器过滤噪声和语音信号来实现的，滤波器的形式为：</p>
<img src="https://cdn.jsdelivr.net/gh/Gavin-rep/Pictures@master/image-20250225221505421.png" alt="image-20250225221505421" style="zoom:50%;" />

<p>其中$r_1…r_4$ 中的每一个均是随机均匀分布在$[\frac{-3}{8},\frac{3}{8}]$ 范围内的。通过改变混合信号的最终电平来实现对信号幅度的鲁棒性。</p>
<p>​	我们总共有 6 小时的语音和 4 小时的噪声数据，通过使用增益和滤波器的各种组合，并将数据重新采样到 40 kHz 到 54 kHz 之间的频率，我们用这些数据来产生 140 小时的噪声语音。</p>
<h3 id="B-优化阶段"><a href="#B-优化阶段" class="headerlink" title="B. 优化阶段"></a>B. 优化阶段</h3><p>​	用于训练的损失函数决定了当网络无法精确确定正确增益时，它如何在过度衰减和不足衰减之间权衡。尽管在优化 [0,1] 范围内的值时，通常使用二元交叉熵（binary cross-entropy）函数，但对于增益而言，这种方法效果不佳，因为它无法匹配增益的感知效果。因此，对于增益估计值 $\hat{g}_b$ 和相应的真实值 $g_b$，我们采用以下损失函数进行训练：</p>
<img src="https://cdn.jsdelivr.net/gh/Gavin-rep/Pictures@master/image-20250225221808788.png" alt="image-20250225221808788" style="zoom:50%;" />

<p>其中，指数参数 $\gamma$ 是一个感知控制参数，它决定了噪声抑制的激进程度。由于当 $lim_{\gamma \to 0} \frac{x^{\gamma} -1}{\gamma} &#x3D; \log(x)$，因此当 γ→0\gamma \to 0 时，损失函数$lim_{\gamma \to 0}L(g_b, \hat{g}_b)$ 近似于对数能量的均方误差（MSE）。然而，由于增益没有设定下限，这会导致过度抑制。在实践中，选择 $\gamma &#x3D; \frac{1}{2}$ 可以在抑制强度和音质保留之间取得良好平衡，相当于最小化四次方根能量的均方误差。此外，在某些情况下，特定频带内可能既没有噪声也没有语音。例如，当输入信号是静音或者信号经过低通滤波后，高频段没有能量时，这种情况很常见。当发生这种情况时，真实增益值会被显式标记为未定义，并且损失函数不会对该增益值进行计算，以避免影响训练过程。</p>
<p>​	对于网络的 VAD 输出，我们使用标准的交叉熵损失函数。使用带有 Tensorflow4 后端的 Keras3 库进行训练。</p>
<h3 id="3-增益平滑"><a href="#3-增益平滑" class="headerlink" title="3. 增益平滑"></a>3. 增益平滑</h3><p>当使用增益$\hat{g}_b$ 进行噪声抑制时，输出信号有时会听起来过于干燥，缺乏预期的最低混响级别。这个问题可以通过限制增益在各帧之间的衰减来轻松解决。平滑后的增益 $\tilde{g}_b$ 是通过以下方式获得的：</p>
<img src="https://cdn.jsdelivr.net/gh/Gavin-rep/Pictures@master/image-20250225222242621.png" alt="image-20250225222242621" style="zoom:50%;" />

<p>其中$\tilde{g}_b^{(prev)}$ 是前一帧的滤波增益，衰减因子 $λ &#x3D; 0.6$ 相当于 135 ms 的混响时间。</p>
<h2 id="4-复杂度分析"><a href="#4-复杂度分析" class="headerlink" title="4. 复杂度分析"></a>4. 复杂度分析</h2><p>​	为了方便部署噪声抑制算法，保持较低的大小和复杂度是非常重要的。执行文件的大小主要由表示神经网络中215个单元所需的87,503个权重决定。为了尽可能减小文件大小，这些权重可以量化为8位而不会损失性能。这样可以使所有权重都适合CPU的L2缓存中。</p>
<p>​	由于每个权重在每帧中仅用于一次乘加操作，神经网络每帧需要175,000次浮点运算（我们将乘加操作计为两个操作），因此实时使用时需要17.5 Mflops。每帧的IFFT和两个FFT大约需要7.5 Mflops，而音调搜索（在12 kHz下操作）需要约10 Mflops。算法的总复杂度大约为40 Mflops，这与全频带语音codec的复杂度相当。</p>
<p>​	该算法的非矢量化C语言实现需要大约1.3%的单个x86核心（Haswell i7-4800MQ）来执行48 kHz单通道噪声抑制。相同浮点代码在1.2 GHz ARM Cortex-A53核心（Raspberry Pi 3）上的实时复杂度为14%。</p>
<p>​	作为对比，文献[9]中16 kHz语音增强方法使用了3个隐藏层，每个隐藏层有2048个单元。该方法需要1250万个权重，导致1600 Mflops的复杂度。即使权重量化为8位，这些权重也无法适配大多数CPU的缓存，实时操作需要约800 MB&#x2F;s的内存带宽。</p>
<h2 id="5-结果"><a href="#5-结果" class="headerlink" title="5. 结果"></a>5. 结果</h2><p>​	我们使用未在训练集中的语音和噪声数据来测试噪声抑制的质量，并将其与SpeexDSP库中的基于MMSE的噪声抑制器进行比较[5]。尽管噪声抑制在48 kHz下运行，但由于宽带PESQ的限制[16]，输出需要重新采样为16 kHz。图5中的客观结果显示，使用深度学习显著提高了质量，尤其对于非平稳噪声类型。通过随意听取样本，也能确认这种改进。图4展示了噪声抑制对一个示例的影响。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Gavin-rep/Pictures@master/image-20250225222750155.png" alt="image-20250225222750155"></p>
<p><img src="https://cdn.jsdelivr.net/gh/Gavin-rep/Pictures@master/image-20250225223218259.png" alt="image-20250225223218259"></p>
<p>​	所提系统的互动演示可以在 <a target="_blank" rel="noopener" href="https://people.xiph.org/~jm/demo/rnnoise/">https://people.xiph.org/~jm/demo/rnnoise/</a> 上找到，包括一个实时的Javascript实现。实现该系统的软件可以通过BSD许可证在 <a target="_blank" rel="noopener" href="https://github.com/xiph/rnnoise/">https://github.com/xiph/rnnoise/</a> 上获得，结果是通过提交哈希值91ef401生成的。</p>
<h2 id="6-结论"><a href="#6-结论" class="headerlink" title="6. 结论"></a>6. 结论</h2><p>​	本文展示了一种结合了基于DSP的技术和深度学习的噪声抑制方法。通过仅将深度学习应用于那些难以调优的噪声抑制部分，问题简化为只需计算22个理想的临界频带增益，这可以通过少量单元高效地完成。频带的粗分辨率问题则通过使用简单的音调滤波器来解决。最终的低复杂度使得该方法适用于移动设备或嵌入式设备，且其延迟足够低，适合用于视频会议系统。</p>
<p>​	我们还展示了该方法的质量明显高于纯信号处理方法。我们认为该技术可以很容易扩展到残余回声抑制，例如通过将远端信号的倒谱或过滤后的远端信号加入输入特征。同样地，通过像文献[17]中那样使用泄漏估计增强输入特征，它应该适用于麦克风阵列的后处理滤波。</p>
<img src="https://cdn.jsdelivr.net/gh/Gavin-rep/Pictures@master/image-20250225222914216.png" alt="image-20250225222914216" style="zoom:50%;" /></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="http://example.com">Gavin</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://example.com/2024/12/15/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%EF%BC%9AA%20Hybrid%20DSP:Deep%20Learning%20Approach%20to%20%20Real-Time%20Full-Band%20Speech%20Enhancement/">http://example.com/2024/12/15/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%EF%BC%9AA%20Hybrid%20DSP:Deep%20Learning%20Approach%20to%20%20Real-Time%20Full-Band%20Speech%20Enhancement/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://example.com" target="_blank">Gavin</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%BC%80%E6%BA%90%E4%BB%A3%E7%A0%81/">开源代码</a><a class="post-meta__tags" href="/tags/%E8%AF%AD%E9%9F%B3%E5%A2%9E%E5%BC%BA/">语音增强</a><a class="post-meta__tags" href="/tags/%E9%99%8D%E5%99%AA/">降噪</a><a class="post-meta__tags" href="/tags/%E5%AE%9E%E6%97%B6/">实时</a></div><div class="post_share"><div class="social-share" data-image="https://i.ibb.co/VYX8yFsD/image.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2025/03/03/%E6%AF%94%E8%B5%9B%E7%9B%B8%E5%85%B3%EF%BC%9ADCASE%202019%20Task3%20SELD/" title="比赛相关：DCASE 2019 Task3 SELD"><img class="cover" src="https://i.ibb.co/ZRtszJys/image.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">比赛相关：DCASE 2019 Task3 SELD</div></div></a></div><div class="next-post pull-right"><a href="/2024/11/19/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%EF%BC%9AMasked%20Autoencoders%20that%20listen/" title="文献阅读: Masked Autoencoders that Listen"><img class="cover" src="https://i.ibb.co/9HZr35S/image.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">文献阅读: Masked Autoencoders that Listen</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2024/05/06/%20%20%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB-%20Real-time%20implementation%20and%20explainable%20AI%20analysis%20of%20delayless%20CNN-based%20selective%20fixed-filter%20active%20noise%20control/" title="文献阅读: Real-time implementation and explainable AI analysis of delayless CNN-based selective fixed-filter active noise control"><img class="cover" src="https://i.ibb.co/rk6B9g0/image.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-05-06</div><div class="title">文献阅读: Real-time implementation and explainable AI analysis of delayless CNN-based selective fixed-filter active noise control</div></div></a></div><div><a href="/2024/05/06/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%EF%BC%9A%20Transferable%20Latent%20of%20CNN-Based%20Selective%20Fixed-Filter%20Active%20Noise%20Control/" title="文献阅读: Transferable Latent of CNN-Based Selective Fixed-Filter Active Noise Control"><img class="cover" src="https://i.ibb.co/xSTFTsh/image.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-05-06</div><div class="title">文献阅读: Transferable Latent of CNN-Based Selective Fixed-Filter Active Noise Control</div></div></a></div><div><a href="/2024/04/23/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%EF%BC%9AA%20Hybrid%20SFANC-FxNLMS%20Algorithm%20for%20Active%20Noise%20Control%20based%20on%20Deep%20Learning/" title="文献阅读: A Hybrid SFANC-FxNLMS Algorithm for Active Noise Control based on Deep Learning"><img class="cover" src="https://i.ibb.co/5GmwJBS/image.png	" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-04-23</div><div class="title">文献阅读: A Hybrid SFANC-FxNLMS Algorithm for Active Noise Control based on Deep Learning</div></div></a></div><div><a href="/2024/05/05/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%EF%BC%9ADEEP%20GENERATIVE%20FIXED-FILTER%20ACTIVE%20NOISE%20CONTROL/" title="文献阅读: DEEP GENERATIVE FIXED-FILTER ACTIVE NOISE CONTROL"><img class="cover" src="https://i.ibb.co/LSLjfkw/image.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-05-05</div><div class="title">文献阅读: DEEP GENERATIVE FIXED-FILTER ACTIVE NOISE CONTROL</div></div></a></div><div><a href="/2024/08/15/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%EF%BC%9ADeep%20root%20music%20algorithm%20for%20data-driven%20DoA%20estimation/" title="文献阅读: SubspaceNet: Deep root music algorithm for data-driven DoA estimation"><img class="cover" src="https://i.ibb.co/8xsnM1g/image.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-08-15</div><div class="title">文献阅读: SubspaceNet: Deep root music algorithm for data-driven DoA estimation</div></div></a></div><div><a href="/2024/07/03/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%EF%BC%9AGFANC-Kalman-%20Generative%20Fixed-Filter%20Active%20%20Noise%20Control%20With%20CNN-Kalman%20Filtering/" title="文献阅读: GFANC-Kalman: Generative Fixed-Filter Active  Noise Control With CNN-Kalman Filtering"><img class="cover" src="https://i.ibb.co/VQ54Jw6/image.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-07-03</div><div class="title">文献阅读: GFANC-Kalman: Generative Fixed-Filter Active  Noise Control With CNN-Kalman Filtering</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://i.ibb.co/0fP2mb0/image.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Gavin</div><div class="author-info__description">我的过去常常追赶着我</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">30</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">19</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">3</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/alexandergwm"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/alexandergwm" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:wenmiaogao@163.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">May you stay young forever, do the thing in your own zone.</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%91%98%E8%A6%81"><span class="toc-number">1.</span> <span class="toc-text">摘要</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E4%BB%8B%E7%BB%8D"><span class="toc-number">2.</span> <span class="toc-text">1.介绍</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E4%BF%A1%E5%8F%B7%E6%A8%A1%E5%9E%8B"><span class="toc-number">3.</span> <span class="toc-text">2.信号模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#A-Band-Structure"><span class="toc-number">3.1.</span> <span class="toc-text">A. Band Structure</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#B-Pitch-filtering"><span class="toc-number">3.2.</span> <span class="toc-text">B. Pitch filtering</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#C-%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96"><span class="toc-number">3.3.</span> <span class="toc-text">C. 特征提取</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%BB%93%E6%9E%84"><span class="toc-number">4.</span> <span class="toc-text">3. 深度学习结构</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#A-%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE"><span class="toc-number">4.1.</span> <span class="toc-text">A. 训练数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#B-%E4%BC%98%E5%8C%96%E9%98%B6%E6%AE%B5"><span class="toc-number">4.2.</span> <span class="toc-text">B. 优化阶段</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E5%A2%9E%E7%9B%8A%E5%B9%B3%E6%BB%91"><span class="toc-number">4.3.</span> <span class="toc-text">3. 增益平滑</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-%E5%A4%8D%E6%9D%82%E5%BA%A6%E5%88%86%E6%9E%90"><span class="toc-number">5.</span> <span class="toc-text">4. 复杂度分析</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-%E7%BB%93%E6%9E%9C"><span class="toc-number">6.</span> <span class="toc-text">5. 结果</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-%E7%BB%93%E8%AE%BA"><span class="toc-number">7.</span> <span class="toc-text">6. 结论</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2025/03/03/%E6%AF%94%E8%B5%9B%E7%9B%B8%E5%85%B3%EF%BC%9ADCASE%202019%20Task3%20SELD/" title="比赛相关：DCASE 2019 Task3 SELD"><img src="https://i.ibb.co/ZRtszJys/image.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="比赛相关：DCASE 2019 Task3 SELD"/></a><div class="content"><a class="title" href="/2025/03/03/%E6%AF%94%E8%B5%9B%E7%9B%B8%E5%85%B3%EF%BC%9ADCASE%202019%20Task3%20SELD/" title="比赛相关：DCASE 2019 Task3 SELD">比赛相关：DCASE 2019 Task3 SELD</a><time datetime="2025-03-03T14:26:06.037Z" title="发表于 2025-03-03 22:26:06">2025-03-03</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/12/15/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%EF%BC%9AA%20Hybrid%20DSP:Deep%20Learning%20Approach%20to%20%20Real-Time%20Full-Band%20Speech%20Enhancement/" title="文献阅读: A Hybrid DSP/Deep Learning Approach to  Real-Time Full-Band Speech Enhancement"><img src="https://i.ibb.co/VYX8yFsD/image.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="文献阅读: A Hybrid DSP/Deep Learning Approach to  Real-Time Full-Band Speech Enhancement"/></a><div class="content"><a class="title" href="/2024/12/15/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%EF%BC%9AA%20Hybrid%20DSP:Deep%20Learning%20Approach%20to%20%20Real-Time%20Full-Band%20Speech%20Enhancement/" title="文献阅读: A Hybrid DSP/Deep Learning Approach to  Real-Time Full-Band Speech Enhancement">文献阅读: A Hybrid DSP/Deep Learning Approach to  Real-Time Full-Band Speech Enhancement</a><time datetime="2024-12-15T04:12:53.312Z" title="发表于 2024-12-15 12:12:53">2024-12-15</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/11/19/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%EF%BC%9AMasked%20Autoencoders%20that%20listen/" title="文献阅读: Masked Autoencoders that Listen"><img src="https://i.ibb.co/9HZr35S/image.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="文献阅读: Masked Autoencoders that Listen"/></a><div class="content"><a class="title" href="/2024/11/19/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%EF%BC%9AMasked%20Autoencoders%20that%20listen/" title="文献阅读: Masked Autoencoders that Listen">文献阅读: Masked Autoencoders that Listen</a><time datetime="2024-11-19T13:34:57.816Z" title="发表于 2024-11-19 21:34:57">2024-11-19</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/11/17/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%EF%BC%9AMasked%20Autoencoders%20Are%20Scalable%20Vision%20Learners%20/" title="文献阅读: Masked Autoencoders Are Scalable Vision Learners"><img src="https://i.ibb.co/gD7cJGh/image.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="文献阅读: Masked Autoencoders Are Scalable Vision Learners"/></a><div class="content"><a class="title" href="/2024/11/17/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%EF%BC%9AMasked%20Autoencoders%20Are%20Scalable%20Vision%20Learners%20/" title="文献阅读: Masked Autoencoders Are Scalable Vision Learners">文献阅读: Masked Autoencoders Are Scalable Vision Learners</a><time datetime="2024-11-17T12:30:01.804Z" title="发表于 2024-11-17 20:30:01">2024-11-17</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/10/27/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%20-%20Robustness%20and%20Regularization%20of%20Personal%20Audio%20Systems/" title="文献阅读: Robustness and Regularization of Personal Audio Systems"><img src="https://i.ibb.co/c1YpYsm/image.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="文献阅读: Robustness and Regularization of Personal Audio Systems"/></a><div class="content"><a class="title" href="/2024/10/27/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%20-%20Robustness%20and%20Regularization%20of%20Personal%20Audio%20Systems/" title="文献阅读: Robustness and Regularization of Personal Audio Systems">文献阅读: Robustness and Regularization of Personal Audio Systems</a><time datetime="2024-10-27T13:47:25.740Z" title="发表于 2024-10-27 21:47:25">2024-10-27</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2025 By Gavin</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">Have a nice day!</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, '']
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typesetPromise()
}</script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex/dist/contrib/copy-tex.min.js"></script><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', { class: 'katex-wrap'})
  })
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>